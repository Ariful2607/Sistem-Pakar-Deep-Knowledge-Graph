{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBN architecture\n",
    "class DBN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(DBN, self).__init__()\n",
    "        self.rbm1 = RBM(input_dim, hidden_dim)\n",
    "        self.rbm2 = RBM(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.rbm1(x))\n",
    "        x = torch.sigmoid(self.rbm2(x))\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# RBM layer\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, visible_dim, hidden_dim):\n",
    "        super(RBM, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(visible_dim, hidden_dim))\n",
    "        self.visible_bias = nn.Parameter(torch.randn(visible_dim))\n",
    "        self.hidden_bias = nn.Parameter(torch.randn(hidden_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        p_hidden_given_visible = torch.sigmoid(torch.matmul(x, self.W) + self.hidden_bias)\n",
    "        sampled_hidden = torch.bernoulli(p_hidden_given_visible)\n",
    "        p_visible_given_hidden = torch.sigmoid(torch.matmul(sampled_hidden, self.W.t()) + self.visible_bias)\n",
    "        return p_visible_given_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Neo4j and retrieve knowledge graph vectors\n",
    "class Neo4jDataLoader:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    \n",
    "    def get_vectors(self):\n",
    "        with self._driver.session() as session:\n",
    "            # query = \"MATCH (node:Entity) RETURN node.vector AS vector\"\n",
    "            query = \"MATCH (n) RETURN n.Vector AS vector\"\n",
    "            result = session.run(query)\n",
    "            vectors = [record['vector'] for record in result]\n",
    "        return torch.tensor(vectors)\n",
    "neo4j_loader = Neo4jDataLoader(uri=\"bolt://34.101.159.175:7687\", user=\"neo4j\", password=\"unej1234\")\n",
    "data = neo4j_loader.get_vectors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://34.101.159.175:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"unej1234\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"MATCH (n) RETURN n.label AS label\")\n",
    "    label = pd.DataFrame([record.values() for record in result], columns=result.keys())\n",
    "    \n",
    "# Extract the values from the 'label' column and convert to a one-dimensional list\n",
    "label_values = label['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4801,  0.6460, -0.9932,  ..., -0.4361, -0.8677, -1.7822],\n",
       "        [ 0.2617,  0.0716,  0.0499,  ..., -1.2279, -0.1212, -1.0645],\n",
       "        [ 0.0228,  0.3414, -0.4033,  ..., -0.0076, -0.9350, -1.0907],\n",
       "        ...,\n",
       "        [-0.4614,  0.1860,  0.3704,  ..., -1.3313, -0.4901, -0.2599],\n",
       "        [-0.2461,  0.1481, -0.3852,  ..., -0.1658, -0.8010, -1.0049],\n",
       "        [ 1.8812,  0.1237, -2.4698,  ..., -1.5062, -2.7816,  0.4476]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [0.78980684]\n",
      "1        [1.4231793]\n",
      "2        [0.9084352]\n",
      "3      [-0.38928694]\n",
      "4      [-0.74302006]\n",
      "           ...      \n",
      "100      [0.6022621]\n",
      "101     [0.13106883]\n",
      "102     [-1.4819928]\n",
      "103     [0.06058532]\n",
      "104    [-0.05674773]\n",
      "Name: embeddings, Length: 105, dtype: object\n",
      "tensor([[ 0.7898],\n",
      "        [ 1.4232],\n",
      "        [ 0.9084],\n",
      "        [-0.3893],\n",
      "        [-0.7430],\n",
      "        [ 0.4056],\n",
      "        [-0.4913],\n",
      "        [-0.6787],\n",
      "        [-0.5073],\n",
      "        [ 0.9615],\n",
      "        [ 0.9742],\n",
      "        [-2.0069],\n",
      "        [-0.1508],\n",
      "        [ 0.1580],\n",
      "        [-0.7407],\n",
      "        [ 0.5534],\n",
      "        [-0.2743],\n",
      "        [ 0.2260],\n",
      "        [-0.5307],\n",
      "        [ 1.1660],\n",
      "        [ 0.8677],\n",
      "        [ 0.5838],\n",
      "        [-0.7661],\n",
      "        [ 0.4820],\n",
      "        [-0.8932],\n",
      "        [-0.1494],\n",
      "        [ 0.6777],\n",
      "        [-0.3936],\n",
      "        [-0.1938],\n",
      "        [ 0.5743],\n",
      "        [ 0.0045],\n",
      "        [ 1.0079],\n",
      "        [-0.9604],\n",
      "        [ 0.5007],\n",
      "        [-0.8760],\n",
      "        [-0.7847],\n",
      "        [-0.9132],\n",
      "        [-1.1953],\n",
      "        [ 0.8844],\n",
      "        [ 0.8826],\n",
      "        [-0.1982],\n",
      "        [-0.0819],\n",
      "        [ 1.0530],\n",
      "        [ 0.0608],\n",
      "        [-0.2840],\n",
      "        [-0.0410],\n",
      "        [-1.4808],\n",
      "        [-0.4054],\n",
      "        [-0.1146],\n",
      "        [ 0.3295],\n",
      "        [ 0.7105],\n",
      "        [ 1.0812],\n",
      "        [ 1.4352],\n",
      "        [-0.1861],\n",
      "        [-0.3789],\n",
      "        [-0.1089],\n",
      "        [-0.4642],\n",
      "        [-0.1467],\n",
      "        [ 1.3314],\n",
      "        [-0.8804],\n",
      "        [-0.1466],\n",
      "        [ 1.5235],\n",
      "        [-0.4957],\n",
      "        [-0.5696],\n",
      "        [ 0.0575],\n",
      "        [ 0.9793],\n",
      "        [ 0.1374],\n",
      "        [ 0.2787],\n",
      "        [ 0.6891],\n",
      "        [ 0.5568],\n",
      "        [ 0.9538],\n",
      "        [ 0.9273],\n",
      "        [ 0.2387],\n",
      "        [ 0.6047],\n",
      "        [ 0.0190],\n",
      "        [ 0.1705],\n",
      "        [-0.3910],\n",
      "        [ 0.6633],\n",
      "        [-0.2638],\n",
      "        [-0.2053],\n",
      "        [ 1.4022],\n",
      "        [ 0.8980],\n",
      "        [ 1.2415],\n",
      "        [ 1.3643],\n",
      "        [ 0.3272],\n",
      "        [ 0.1859],\n",
      "        [ 1.5061],\n",
      "        [-0.3341],\n",
      "        [-1.0521],\n",
      "        [-0.4798],\n",
      "        [-0.2872],\n",
      "        [ 0.6798],\n",
      "        [ 0.2213],\n",
      "        [ 0.3694],\n",
      "        [ 1.4684],\n",
      "        [-0.3246],\n",
      "        [-0.8917],\n",
      "        [-1.1652],\n",
      "        [-0.6061],\n",
      "        [ 0.0510],\n",
      "        [ 0.6023],\n",
      "        [ 0.1311],\n",
      "        [-1.4820],\n",
      "        [ 0.0606],\n",
      "        [-0.0567]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ariful\\AppData\\Local\\Temp\\ipykernel_2232\\1662484291.py:33: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  embeddings_tensor = torch.tensor(df['embeddings'].to_list())\n"
     ]
    }
   ],
   "source": [
    "# Define a Word2Vec model (you need to define this as you did before)\n",
    "sentences = [str(text).split() for text in label_values]\n",
    "model = Word2Vec(sentences, vector_size=1, window=5, min_count=1, sg=0)\n",
    "\n",
    "# Function to get embeddings for a list of words\n",
    "def get_sentence_embedding(word_list):\n",
    "    word_vectors = [model.wv[word] for word in word_list if word in model.wv.key_to_index]\n",
    "    \n",
    "    if word_vectors:\n",
    "        sentence_embedding = sum(word_vectors)\n",
    "        return sentence_embedding\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'text_data': label_values}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the text_data column into lists of words and apply the function to each row\n",
    "df['text_data'] = df['text_data'].apply(lambda x: x.split() if x is not None else [])\n",
    "df['embeddings'] = df['text_data'].apply(lambda x: get_sentence_embedding(x) if x else None)\n",
    "\n",
    "print(df['embeddings'])\n",
    "\n",
    "# # Filter out rows where embeddings are not available\n",
    "# df = df.dropna(subset=['embeddings'])\n",
    "\n",
    "# Replace rows where embeddings are not available with a default value (e.g., zeros)\n",
    "default_embedding = np.zeros(1)  # Replace with your desired default value\n",
    "df['embeddings'] = df['embeddings'].apply(lambda x: x if x is not None else default_embedding)\n",
    "\n",
    "# Convert embeddings to a PyTorch tensor\n",
    "embeddings_tensor = torch.tensor(df['embeddings'].to_list())\n",
    "\n",
    "print(embeddings_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([105, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to retrieve routing information\n"
     ]
    },
    {
     "ename": "ServiceUnavailable",
     "evalue": "Unable to retrieve routing information",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/100], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 38\u001b[0m     train_dbn()\n",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m, in \u001b[0;36mtrain_dbn\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Connect to Neo4j and retrieve data\u001b[39;00m\n\u001b[0;32m     13\u001b[0m neo4j_loader \u001b[38;5;241m=\u001b[39m Neo4jDataLoader(uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneo4j://localhost:7687\u001b[39m\u001b[38;5;124m\"\u001b[39m, user\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneo4j\u001b[39m\u001b[38;5;124m\"\u001b[39m, password\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12345678\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m data \u001b[38;5;241m=\u001b[39m neo4j_loader\u001b[38;5;241m.\u001b[39mget_vectors()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Load labels for your data\u001b[39;00m\n\u001b[0;32m     17\u001b[0m labels \u001b[38;5;241m=\u001b[39m embeddings_tensor\n",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m, in \u001b[0;36mNeo4jDataLoader.get_vectors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_driver\u001b[38;5;241m.\u001b[39msession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# query = \"MATCH (node:Entity) RETURN node.vector AS vector\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMATCH (n) RETURN n.Vector AS vector\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m     result \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mrun(query)\n\u001b[0;32m     11\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m result]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(vectors)\n",
      "File \u001b[1;32mc:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:302\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_result\u001b[38;5;241m.\u001b[39m_buffer_all()\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection:\n\u001b[1;32m--> 302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdefault_access_mode)\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    304\u001b[0m cx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\n",
      "File \u001b[1;32mc:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:130\u001b[0m, in \u001b[0;36mSession._connect\u001b[1;34m(self, access_mode, **acquire_kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     access_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdefault_access_mode\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_connect(\n\u001b[0;32m    131\u001b[0m         access_mode, auth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mauth, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39macquire_kwargs\n\u001b[0;32m    132\u001b[0m     )\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_cancellation(message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_connect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\work\\workspace.py:165\u001b[0m, in \u001b[0;36mWorkspace._connect\u001b[1;34m(self, access_mode, auth, **acquire_kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;66;03m# This is the first time we open a connection to a server in a\u001b[39;00m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# cluster environment for this session without explicitly\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;66;03m# we shall use this database explicitly for all subsequent\u001b[39;00m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;66;03m# actions within this session.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  _: <WORKSPACE> resolve home database\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 165\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mupdate_routing_table(\n\u001b[0;32m    166\u001b[0m             database\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdatabase,\n\u001b[0;32m    167\u001b[0m             imp_user\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mimpersonated_user,\n\u001b[0;32m    168\u001b[0m             bookmarks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_bookmarks(),\n\u001b[0;32m    169\u001b[0m             auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    170\u001b[0m             acquisition_timeout\u001b[38;5;241m=\u001b[39macquisition_timeout,\n\u001b[0;32m    171\u001b[0m             database_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_cached_database\n\u001b[0;32m    172\u001b[0m         )\n\u001b[0;32m    173\u001b[0m acquire_kwargs_ \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccess_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: access_mode,\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: acquisition_timeout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliveness_check_timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    180\u001b[0m }\n\u001b[0;32m    181\u001b[0m acquire_kwargs_\u001b[38;5;241m.\u001b[39mupdate(acquire_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:802\u001b[0m, in \u001b[0;36mNeo4jPool.update_routing_table\u001b[1;34m(self, database, imp_user, bookmarks, auth, acquisition_timeout, database_callback)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;66;03m# None of the routers have been successful, so just fail\u001b[39;00m\n\u001b[0;32m    801\u001b[0m log\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to retrieve routing information\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 802\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to retrieve routing information\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mServiceUnavailable\u001b[0m: Unable to retrieve routing information"
     ]
    }
   ],
   "source": [
    "# Main training loop\n",
    "def train_dbn():\n",
    "    # Initialize DBN and other hyperparameters\n",
    "    input_dim = 32  # Adjust based on the dimensionality of your knowledge graph vectors\n",
    "    hidden_dim = 32\n",
    "    output_dim = 2  # Adjust based on your task (e.g., classification)\n",
    "\n",
    "    dbn = DBN(input_dim, hidden_dim, output_dim)\n",
    "    optimizer = optim.Adam(dbn.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Connect to Neo4j and retrieve data\n",
    "    neo4j_loader = Neo4jDataLoader(uri=\"neo4j://localhost:7687\", user=\"neo4j\", password=\"12345678\")\n",
    "    data = neo4j_loader.get_vectors()\n",
    "\n",
    "    # Load labels for your data\n",
    "    labels = embeddings_tensor\n",
    "\n",
    "    # Create a DataLoader to handle batching (if needed)\n",
    "    batch_size = 32  # Adjust based on your dataset size\n",
    "    dataset = TensorDataset(data, labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(100):  # Adjust the number of epochs\n",
    "        total_loss = 0.0\n",
    "        for inputs, targets in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            output = dbn(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/100], Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_dbn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
