{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://34.101.192.24:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"unej1234\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_properties():\n",
    "    with driver.session() as session:\n",
    "        # Cypher query to fetch node properties\n",
    "        query = \"\"\"\n",
    "        MATCH (n)\n",
    "        RETURN n.Vector AS vector, n.label AS label, labels(n) AS kelas, n.abstract AS keterangan\n",
    "        \"\"\"\n",
    "        result = session.run(query)\n",
    "        # Extract properties and store in DataFrame\n",
    "        df = pd.DataFrame([record.values() for record in result], columns=result.keys())\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector</th>\n",
       "      <th>label</th>\n",
       "      <th>kelas</th>\n",
       "      <th>keterangan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.03639092668890953, -0.024370986968278885, -...</td>\n",
       "      <td>Metalaxyl</td>\n",
       "      <td>[Fungisida]</td>\n",
       "      <td>Metalaxyl adalah sejenis fungisida yang diguna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>Penyakit gosong bulir padi, juga dikenal sebag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.032646406441926956, -0.04352227970957756, 0...</td>\n",
       "      <td>Laba laba</td>\n",
       "      <td>[Biologis]</td>\n",
       "      <td>Laba-laba adalah predator umum yang dapat mema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.036355093121528625, 0.043446771800518036, 0...</td>\n",
       "      <td>Trichogramm</td>\n",
       "      <td>[Biologis]</td>\n",
       "      <td>Trichogramma atau parasitoid terkait hadir ada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.036346133798360825, -0.03959878906607628, -...</td>\n",
       "      <td>Acidovorax avenae subsp. avenae</td>\n",
       "      <td>[PatogenPadi]</td>\n",
       "      <td>Acidovorax avenae subsp. avenae adalah bakteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>[0.03919482231140137, -0.031110592186450958, 0...</td>\n",
       "      <td>Penggerek Batang Kuning</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "      <td>Penggerek batang kuning merupakan jenis serang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>[0.03915003314614296, -0.04633839428424835, 0....</td>\n",
       "      <td>Klorpiris</td>\n",
       "      <td>[Pestisida]</td>\n",
       "      <td>Klorpirifos adalah insektisida organofosfat. K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>[0.03914107382297516, -0.029383953660726547, -...</td>\n",
       "      <td>Rayap</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "      <td>Rayap dapat menyerang tanaman di semua tahap p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>[0.03916794806718826, 0.019752727821469307, 0....</td>\n",
       "      <td>Daun berkarat</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>Daun berkarat (pastula) berwarna kuning hingga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>[0.03915898874402046, 0.03670716658234596, -0....</td>\n",
       "      <td>Hawar Pelepah</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>Hawar pelepah padi adalah penyakit yang diseba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                vector  \\\n",
       "0    [0.03639092668890953, -0.024370986968278885, -...   \n",
       "1    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "2    [0.032646406441926956, -0.04352227970957756, 0...   \n",
       "3    [0.036355093121528625, 0.043446771800518036, 0...   \n",
       "4    [0.036346133798360825, -0.03959878906607628, -...   \n",
       "..                                                 ...   \n",
       "138  [0.03919482231140137, -0.031110592186450958, 0...   \n",
       "139  [0.03915003314614296, -0.04633839428424835, 0....   \n",
       "140  [0.03914107382297516, -0.029383953660726547, -...   \n",
       "141  [0.03916794806718826, 0.019752727821469307, 0....   \n",
       "142  [0.03915898874402046, 0.03670716658234596, -0....   \n",
       "\n",
       "                               label           kelas  \\\n",
       "0                          Metalaxyl     [Fungisida]   \n",
       "1                       Gosong bulir  [PenyakitPadi]   \n",
       "2                          Laba laba      [Biologis]   \n",
       "3                        Trichogramm      [Biologis]   \n",
       "4    Acidovorax avenae subsp. avenae   [PatogenPadi]   \n",
       "..                               ...             ...   \n",
       "138          Penggerek Batang Kuning      [HamaPadi]   \n",
       "139                        Klorpiris     [Pestisida]   \n",
       "140                            Rayap      [HamaPadi]   \n",
       "141                    Daun berkarat        [Gejala]   \n",
       "142                    Hawar Pelepah  [PenyakitPadi]   \n",
       "\n",
       "                                            keterangan  \n",
       "0    Metalaxyl adalah sejenis fungisida yang diguna...  \n",
       "1    Penyakit gosong bulir padi, juga dikenal sebag...  \n",
       "2    Laba-laba adalah predator umum yang dapat mema...  \n",
       "3    Trichogramma atau parasitoid terkait hadir ada...  \n",
       "4    Acidovorax avenae subsp. avenae adalah bakteri...  \n",
       "..                                                 ...  \n",
       "138  Penggerek batang kuning merupakan jenis serang...  \n",
       "139  Klorpirifos adalah insektisida organofosfat. K...  \n",
       "140  Rayap dapat menyerang tanaman di semua tahap p...  \n",
       "141  Daun berkarat (pastula) berwarna kuning hingga...  \n",
       "142  Hawar pelepah padi adalah penyakit yang diseba...  \n",
       "\n",
       "[143 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df = extract_node_properties()\n",
    "cleaned_kelas = node_df['kelas'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "node_df['kelas'] = cleaned_kelas\n",
    "node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_vector</th>\n",
       "      <th>source_label</th>\n",
       "      <th>source_class</th>\n",
       "      <th>relationship_type</th>\n",
       "      <th>target_vector</th>\n",
       "      <th>target_label</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03818255290389061, -0.015258912928402424, -...</td>\n",
       "      <td>Bulir terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03753756731748581, 0.005460740067064762, -0...</td>\n",
       "      <td>Bulir pecah</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03612148016691208, 0.0048484764993190765, 0...</td>\n",
       "      <td>Bulir berubah warna</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>terkenaPatogen</td>\n",
       "      <td>[0.03752860799431801, 0.022415179759263992, 0....</td>\n",
       "      <td>Tilletia barclayana</td>\n",
       "      <td>[PatogenPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>diberikanFungisida</td>\n",
       "      <td>[0.03760923072695732, -0.030174778774380684, 0...</td>\n",
       "      <td>Pyraclostrobin</td>\n",
       "      <td>[Fungisida]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>[0.03919482231140137, -0.031110592186450958, 0...</td>\n",
       "      <td>Penggerek Batang Kuning</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.038021307438611984, -0.010079000145196915, ...</td>\n",
       "      <td>Malai terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>[0.03919482231140137, -0.031110592186450958, 0...</td>\n",
       "      <td>Penggerek Batang Kuning</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.033894460648298264, -0.014245453290641308, ...</td>\n",
       "      <td>Daun terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>[0.03914107382297516, -0.029383953660726547, -...</td>\n",
       "      <td>Rayap</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03758235648274422, 0.02068854123353958, 0.0...</td>\n",
       "      <td>Batang rapuh</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>[0.03914107382297516, -0.029383953660726547, -...</td>\n",
       "      <td>Rayap</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03786005824804306, -0.004899086430668831, 0...</td>\n",
       "      <td>Akar berlubang</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>[0.03915898874402046, 0.03670716658234596, -0....</td>\n",
       "      <td>Hawar Pelepah</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03823630139231682, -0.01698555052280426, 0....</td>\n",
       "      <td>Pelepah mengalami kerusakan</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_vector  \\\n",
       "0    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "1    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "2    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "3    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "4    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "..                                                 ...   \n",
       "249  [0.03919482231140137, -0.031110592186450958, 0...   \n",
       "250  [0.03919482231140137, -0.031110592186450958, 0...   \n",
       "251  [0.03914107382297516, -0.029383953660726547, -...   \n",
       "252  [0.03914107382297516, -0.029383953660726547, -...   \n",
       "253  [0.03915898874402046, 0.03670716658234596, -0....   \n",
       "\n",
       "                source_label    source_class   relationship_type  \\\n",
       "0               Gosong bulir  [PenyakitPadi]      memilikiGejala   \n",
       "1               Gosong bulir  [PenyakitPadi]      memilikiGejala   \n",
       "2               Gosong bulir  [PenyakitPadi]      memilikiGejala   \n",
       "3               Gosong bulir  [PenyakitPadi]      terkenaPatogen   \n",
       "4               Gosong bulir  [PenyakitPadi]  diberikanFungisida   \n",
       "..                       ...             ...                 ...   \n",
       "249  Penggerek Batang Kuning      [HamaPadi]      memilikiGejala   \n",
       "250  Penggerek Batang Kuning      [HamaPadi]      memilikiGejala   \n",
       "251                    Rayap      [HamaPadi]      memilikiGejala   \n",
       "252                    Rayap      [HamaPadi]      memilikiGejala   \n",
       "253            Hawar Pelepah  [PenyakitPadi]      memilikiGejala   \n",
       "\n",
       "                                         target_vector  \\\n",
       "0    [0.03818255290389061, -0.015258912928402424, -...   \n",
       "1    [0.03753756731748581, 0.005460740067064762, -0...   \n",
       "2    [0.03612148016691208, 0.0048484764993190765, 0...   \n",
       "3    [0.03752860799431801, 0.022415179759263992, 0....   \n",
       "4    [0.03760923072695732, -0.030174778774380684, 0...   \n",
       "..                                                 ...   \n",
       "249  [0.038021307438611984, -0.010079000145196915, ...   \n",
       "250  [0.033894460648298264, -0.014245453290641308, ...   \n",
       "251  [0.03758235648274422, 0.02068854123353958, 0.0...   \n",
       "252  [0.03786005824804306, -0.004899086430668831, 0...   \n",
       "253  [0.03823630139231682, -0.01698555052280426, 0....   \n",
       "\n",
       "                    target_label   target_class  \n",
       "0          Bulir terdapat bercak       [Gejala]  \n",
       "1                    Bulir pecah       [Gejala]  \n",
       "2            Bulir berubah warna       [Gejala]  \n",
       "3            Tilletia barclayana  [PatogenPadi]  \n",
       "4                 Pyraclostrobin    [Fungisida]  \n",
       "..                           ...            ...  \n",
       "249        Malai terdapat bercak       [Gejala]  \n",
       "250         Daun terdapat bercak       [Gejala]  \n",
       "251                 Batang rapuh       [Gejala]  \n",
       "252               Akar berlubang       [Gejala]  \n",
       "253  Pelepah mengalami kerusakan       [Gejala]  \n",
       "\n",
       "[254 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_node_properties_and_relationships():\n",
    "    with driver.session() as session:\n",
    "        # Cypher query to fetch node properties and relationships\n",
    "        query = \"\"\"\n",
    "            MATCH (n)-[r]->(m)\n",
    "            RETURN n.Vector AS source_vector, n.label AS source_label, labels(n) AS source_class, \n",
    "                type(r) AS relationship_type,\n",
    "                m.Vector AS target_vector, m.label AS target_label, labels(m) AS target_class\n",
    "        \"\"\"\n",
    "        result = session.run(query)\n",
    "        # Extract properties and relationships and store in DataFrame\n",
    "        df = pd.DataFrame([record.values() for record in result], columns=result.keys())\n",
    "        # Clean labels\n",
    "        df['source_class'] = df['source_class'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "        df['target_class'] = df['target_class'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "        return df\n",
    "\n",
    "# Call the function to extract node properties and relationships\n",
    "Rice_KG_df = extract_node_properties_and_relationships()\n",
    "\n",
    "# Print the DataFrame\n",
    "Rice_KG_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_vector</th>\n",
       "      <th>source_label</th>\n",
       "      <th>source_class</th>\n",
       "      <th>relationship_type</th>\n",
       "      <th>target_vector</th>\n",
       "      <th>target_label</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.03818255290389061, -0.015258912928402424, -...</td>\n",
       "      <td>Bulir terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.03753756731748581, 0.005460740067064762, -0...</td>\n",
       "      <td>Bulir pecah</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.03612148016691208, 0.0048484764993190765, 0...</td>\n",
       "      <td>Bulir berubah warna</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.03656195476651192, 0.02377898246049881, 0.0...</td>\n",
       "      <td>Bulir mengalami kerusakan</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.038021307438611984, -0.010079000145196915, ...</td>\n",
       "      <td>Malai terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03643496334552765, -0.020186755806207657, -...</td>\n",
       "      <td>Garis Merah</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>[0.038021307438611984, -0.010079000145196915, ...</td>\n",
       "      <td>Malai terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03919482231140137, -0.031110592186450958, 0...</td>\n",
       "      <td>Penggerek Batang Kuning</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>[0.033894460648298264, -0.014245453290641308, ...</td>\n",
       "      <td>Daun terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03919482231140137, -0.031110592186450958, 0...</td>\n",
       "      <td>Penggerek Batang Kuning</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>[0.03758235648274422, 0.02068854123353958, 0.0...</td>\n",
       "      <td>Batang rapuh</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03914107382297516, -0.029383953660726547, -...</td>\n",
       "      <td>Rayap</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>[0.03786005824804306, -0.004899086430668831, 0...</td>\n",
       "      <td>Akar berlubang</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03914107382297516, -0.029383953660726547, -...</td>\n",
       "      <td>Rayap</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>[0.03823630139231682, -0.01698555052280426, 0....</td>\n",
       "      <td>Pelepah mengalami kerusakan</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03915898874402046, 0.03670716658234596, -0....</td>\n",
       "      <td>Hawar Pelepah</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_vector  \\\n",
       "0    [0.03818255290389061, -0.015258912928402424, -...   \n",
       "1    [0.03753756731748581, 0.005460740067064762, -0...   \n",
       "2    [0.03612148016691208, 0.0048484764993190765, 0...   \n",
       "3    [0.03656195476651192, 0.02377898246049881, 0.0...   \n",
       "4    [0.038021307438611984, -0.010079000145196915, ...   \n",
       "..                                                 ...   \n",
       "131  [0.038021307438611984, -0.010079000145196915, ...   \n",
       "132  [0.033894460648298264, -0.014245453290641308, ...   \n",
       "133  [0.03758235648274422, 0.02068854123353958, 0.0...   \n",
       "134  [0.03786005824804306, -0.004899086430668831, 0...   \n",
       "135  [0.03823630139231682, -0.01698555052280426, 0....   \n",
       "\n",
       "                    source_label source_class relationship_type  \\\n",
       "0          Bulir terdapat bercak     [Gejala]    memilikiGejala   \n",
       "1                    Bulir pecah     [Gejala]    memilikiGejala   \n",
       "2            Bulir berubah warna     [Gejala]    memilikiGejala   \n",
       "3      Bulir mengalami kerusakan     [Gejala]    memilikiGejala   \n",
       "4          Malai terdapat bercak     [Gejala]    memilikiGejala   \n",
       "..                           ...          ...               ...   \n",
       "131        Malai terdapat bercak     [Gejala]    memilikiGejala   \n",
       "132         Daun terdapat bercak     [Gejala]    memilikiGejala   \n",
       "133                 Batang rapuh     [Gejala]    memilikiGejala   \n",
       "134               Akar berlubang     [Gejala]    memilikiGejala   \n",
       "135  Pelepah mengalami kerusakan     [Gejala]    memilikiGejala   \n",
       "\n",
       "                                         target_vector  \\\n",
       "0    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "1    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "2    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "3    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "4    [0.03643496334552765, -0.020186755806207657, -...   \n",
       "..                                                 ...   \n",
       "131  [0.03919482231140137, -0.031110592186450958, 0...   \n",
       "132  [0.03919482231140137, -0.031110592186450958, 0...   \n",
       "133  [0.03914107382297516, -0.029383953660726547, -...   \n",
       "134  [0.03914107382297516, -0.029383953660726547, -...   \n",
       "135  [0.03915898874402046, 0.03670716658234596, -0....   \n",
       "\n",
       "                target_label    target_class  \n",
       "0               Gosong bulir  [PenyakitPadi]  \n",
       "1               Gosong bulir  [PenyakitPadi]  \n",
       "2               Gosong bulir  [PenyakitPadi]  \n",
       "3               Gosong bulir  [PenyakitPadi]  \n",
       "4                Garis Merah  [PenyakitPadi]  \n",
       "..                       ...             ...  \n",
       "131  Penggerek Batang Kuning      [HamaPadi]  \n",
       "132  Penggerek Batang Kuning      [HamaPadi]  \n",
       "133                    Rayap      [HamaPadi]  \n",
       "134                    Rayap      [HamaPadi]  \n",
       "135            Hawar Pelepah  [PenyakitPadi]  \n",
       "\n",
       "[136 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_node_properties_and_relationships():\n",
    "    with driver.session() as session:\n",
    "        # Cypher query to fetch node properties and relationships\n",
    "        query = \"\"\"\n",
    "        MATCH (n)-[r]->(m)\n",
    "            WHERE any(label IN labels(n) WHERE label IN ['Gejala', 'PenyakitPadi', 'HamaPadi']) \n",
    "            AND any(label IN labels(m) WHERE label IN ['Gejala', 'PenyakitPadi', 'HamaPadi'])\n",
    "        RETURN \n",
    "        m.Vector AS source_vector, m.label AS source_label, labels(m) AS source_class, \n",
    "        type(r) AS relationship_type,\n",
    "        n.Vector AS target_vector, n.label AS target_label, labels(n) AS target_class\n",
    "\n",
    "        \"\"\"\n",
    "        result = session.run(query)\n",
    "        # Extract properties and relationships and store in DataFrame\n",
    "        df = pd.DataFrame([record.values() for record in result], columns=result.keys())\n",
    "        # Clean labels\n",
    "        df['source_class'] = df['source_class'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "        df['target_class'] = df['target_class'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "        return df\n",
    "\n",
    "# Call the function to extract node properties and relationships\n",
    "Rice_KG_df = extract_node_properties_and_relationships()\n",
    "\n",
    "# Print the DataFrame\n",
    "Rice_KG_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8536585365853658\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Concatenate source and target vectors as features\n",
    "X = np.concatenate([Rice_KG_df['source_vector'].values.tolist(), Rice_KG_df['target_vector'].values.tolist()], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(Rice_KG_df['relationship_type'])\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", rf_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.17073170731707318\n",
      "Precision: 0.16531165311653118\n",
      "Recall: 0.17073170731707318\n",
      "F1 Score: 0.1661617458279846\n",
      "Confusion Matrix:\n",
      " [[0 0 1 1 1]\n",
      " [0 0 2 2 1]\n",
      " [2 0 1 4 3]\n",
      " [1 1 3 2 3]\n",
      " [0 1 2 6 4]]\n",
      "Cross-validated Accuracy: 0.2798941798941799\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Assuming Rice_KG_df is a pandas DataFrame\n",
    "# Extract features and target variable\n",
    "source_vectors = np.array(Rice_KG_df['source_vector'].tolist())\n",
    "target_vectors = np.array(Rice_KG_df['target_vector'].tolist())\n",
    "relationship_types = Rice_KG_df['relationship_type'].values\n",
    "\n",
    "# Encode relationship types\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_relationship_types = label_encoder.fit_transform(relationship_types)\n",
    "\n",
    "# Concatenate source vectors and encoded relationship types to form X\n",
    "X = np.concatenate([source_vectors, encoded_relationship_types.reshape(-1, 1)], axis=1)\n",
    "\n",
    "# Use KMeans clustering to convert target vectors into discrete classes\n",
    "n_clusters = 5  # You can adjust the number of clusters as needed\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans.fit(target_vectors)\n",
    "y = kmeans.labels_\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model with multiple metrics\n",
    "rf_accuracy = accuracy_score(y_test, y_pred)\n",
    "rf_precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "rf_recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "rf_f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "rf_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "print(\"Precision:\", rf_precision)\n",
    "print(\"Recall:\", rf_recall)\n",
    "print(\"F1 Score:\", rf_f1)\n",
    "print(\"Confusion Matrix:\\n\", rf_conf_matrix)\n",
    "\n",
    "# Optionally, use cross-validation for a better estimate of performance\n",
    "cross_val_scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Accuracy:\", cross_val_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.12195121951219512\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Encode categorical variables if needed\n",
    "label_encoder = LabelEncoder()\n",
    "X_encoded = X.copy()  # Make a copy of X to avoid modifying the original data\n",
    "for i in range(X_encoded.shape[1]):  # Iterate over columns (features)\n",
    "    X_encoded[:, i] = label_encoder.fit_transform(X_encoded[:, i])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train decision tree classifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "dt_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", dt_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4083 - loss: 1.7717  \n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.9599 - loss: 1.7073\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9259 - loss: 1.6381  \n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9133 - loss: 1.5482\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9330 - loss: 1.4186  \n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.9644 - loss: 1.2377\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9565 - loss: 1.0497  \n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.8742 \n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9220 - loss: 0.6881  \n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9280 - loss: 0.5054 \n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.3604 \n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9294 - loss: 0.3769  \n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.3987 \n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9289 - loss: 0.3498  \n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.4882 \n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9478 - loss: 0.2711  \n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.3721 \n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.4048 \n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9300 - loss: 0.3366  \n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8911 - loss: 0.4735  \n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.3635 \n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9350 - loss: 0.3062  \n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9612 - loss: 0.1960  \n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8824 - loss: 0.4860  \n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9392 - loss: 0.2891 \n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9224 - loss: 0.3192  \n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.3908 \n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8836 - loss: 0.4798 \n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.3628 \n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9261 - loss: 0.3070  \n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9433 - loss: 0.2641  \n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9448 - loss: 0.2440 \n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9077 - loss: 0.4013  \n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.4236 \n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9090 - loss: 0.3444  \n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.2945 \n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9144 - loss: 0.3177  \n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9122 - loss: 0.3654  \n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9353 - loss: 0.2508 \n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8950 - loss: 0.4109  \n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.3529 \n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9191 - loss: 0.3191  \n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.3437 \n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9077 - loss: 0.3514  \n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9375 - loss: 0.2394  \n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9294 - loss: 0.2477  \n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168us/step - accuracy: 0.9113 - loss: 0.3488\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9587 - loss: 0.1960  \n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.3290 \n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9383 - loss: 0.2393  \n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9015 - loss: 0.3698 \n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2704 \n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9540 - loss: 0.1958  \n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9272 - loss: 0.2327  \n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9315 - loss: 0.2643 \n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9250 - loss: 0.2687  \n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8957 - loss: 0.3296  \n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9474 - loss: 0.2058  \n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2686\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9428 - loss: 0.2245\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9009 - loss: 0.3468  \n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.2724 \n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9524 - loss: 0.1801  \n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.2778 \n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9302 - loss: 0.2465  \n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9383 - loss: 0.2052  \n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2540 \n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9185 - loss: 0.2702  \n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9547 - loss: 0.1713  \n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9346 - loss: 0.2049  \n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step - accuracy: 0.9026 - loss: 0.2596\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.3385 \n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9061 - loss: 0.2961  \n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9327 - loss: 0.2248  \n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.2002\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9496 - loss: 0.1773  \n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.3294\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9411 - loss: 0.1831 \n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9204 - loss: 0.2278  \n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2323 \n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9250 - loss: 0.1848  \n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.2444 \n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19us/step - accuracy: 0.9541 - loss: 0.1626\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9070 - loss: 0.2496  \n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step - accuracy: 0.9268 - loss: 0.2116\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9070 - loss: 0.2760  \n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.2080 \n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9122 - loss: 0.2239  \n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.1714\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9337 - loss: 0.1922  \n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9405 - loss: 0.1445\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9386 - loss: 0.1801 \n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9415 - loss: 0.2030  \n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9522 - loss: 0.1499 \n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9315 - loss: 0.2117  \n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9217 - loss: 0.2116 \n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9408 - loss: 0.1780  \n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9334 - loss: 0.1698 \n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9403 - loss: 0.1654 \n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9506 - loss: 0.1321  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8929 - loss: 0.5659\n",
      "Accuracy: 0.8928571343421936\n"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Concatenate source and target vectors as features\n",
    "X = np.concatenate([Rice_KG_df['source_vector'].values.tolist(), Rice_KG_df['target_vector'].values.tolist()], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(Rice_KG_df['relationship_type'])\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax') # Output layer with softmax activation for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # Use sparse categorical crossentropy for integer-encoded labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, nn_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", nn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5650 - loss: 1.7795   \n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 1.7069 \n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9129 - loss: 1.5511  \n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9323 - loss: 1.2407 \n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.8730 \n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.4880 \n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.5080 \n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9337 - loss: 0.4059  \n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.9375 - loss: 0.4113\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9263 - loss: 0.3835  \n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.9343 - loss: 0.3715\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.4042 \n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.3196 \n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.2965 \n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.4066 \n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9272 - loss: 0.4252  \n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9298 - loss: 0.3461  \n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.4120 \n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9392 - loss: 0.3286\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.3025 \n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.9457 - loss: 0.2834\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9144 - loss: 0.4120  \n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.1876 \n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.3003 \n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.2455 \n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8935 - loss: 0.4631  \n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9254 - loss: 0.3637\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9346 - loss: 0.3417 \n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9120 - loss: 0.4384 \n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9450 - loss: 0.3152 \n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.4824 \n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9398 - loss: 0.2959  \n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - accuracy: 0.9239 - loss: 0.4488\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9363 - loss: 0.2823 \n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.3722 \n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9243 - loss: 0.3852 \n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.4735\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9346 - loss: 0.3311 \n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.4561\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.3334 \n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.4131 \n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.3645 \n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9483 - loss: 0.3070  \n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.3119 \n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9334 - loss: 0.3482 \n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9441 - loss: 0.2789 \n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.3664 \n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9139 - loss: 0.3970  \n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.2523 \n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9202 - loss: 0.4003 \n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9427 - loss: 0.2969 \n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9524 - loss: 0.2500  \n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9291 - loss: 0.3786  \n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9409 - loss: 0.3378 \n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9224 - loss: 0.3921 \n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.3091 \n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.4378 \n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9522 - loss: 0.2507 \n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9363 - loss: 0.3315 \n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9343 - loss: 0.3054  \n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9096 - loss: 0.4195  \n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.3823\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9026 - loss: 0.4429 \n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9475 - loss: 0.2888 \n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.3690 \n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9126 - loss: 0.3708 \n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9168 - loss: 0.4007  \n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9398 - loss: 0.3427\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.3783 \n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9231 - loss: 0.3497 \n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.4433 \n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9319 - loss: 0.3149 \n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.3817\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9104 - loss: 0.4014 \n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9340 - loss: 0.3568 \n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9373 - loss: 0.3260  \n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9411 - loss: 0.3175  \n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9185 - loss: 0.4376  \n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.3585 \n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9411 - loss: 0.2835 \n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.2601 \n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.3536 \n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9405 - loss: 0.3292 \n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9370 - loss: 0.3515 \n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.9349 - loss: 0.3568\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.3204 \n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9321 - loss: 0.3430 \n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9468 - loss: 0.2940 \n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9317 - loss: 0.3556 \n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9300 - loss: 0.3836 \n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.3433 \n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.4518 \n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9314 - loss: 0.3234 \n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9376 - loss: 0.3155 \n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9172 - loss: 0.4106 \n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9355 - loss: 0.3007  \n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9000 - loss: 0.4910  \n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9256 - loss: 0.3705 \n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.3321 \n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.3254 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.8929 - loss: 0.6665\n",
      "Accuracy: 0.8928571343421936\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "\n",
    "# Reshape the input data to be suitable for a 1D CNN\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(64, 3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(32, 3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(np.unique(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # Use sparse categorical crossentropy for integer-encoded labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, cnn_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", cnn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0s/step - accuracy: 0.5025 - loss: 1.7863\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9359 - loss: 1.7613 \n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9194 - loss: 1.7343  \n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.9116 - loss: 1.7050\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9278 - loss: 1.6687  \n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.9389 - loss: 1.6274\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 1.5914 \n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147us/step - accuracy: 0.9282 - loss: 1.5342\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 1.4778 \n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.9345 - loss: 1.4143\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 1.3553 \n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65us/step - accuracy: 0.9217 - loss: 1.2829\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9204 - loss: 1.2110 \n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9422 - loss: 1.1167  \n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 1.0610 \n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9362 - loss: 0.9648  \n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.9033 \n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9155 - loss: 0.8401  \n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9304 - loss: 0.7531 \n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9337 - loss: 0.6788  \n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9106 - loss: 0.6694 \n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9388 - loss: 0.5630  \n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9155 - loss: 0.5717 \n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9422 - loss: 0.4720  \n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.4761 \n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9392 - loss: 0.4219  \n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.3805 \n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9346 - loss: 0.4014  \n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.9474 - loss: 0.3417\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.4069 \n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9118 - loss: 0.4229  \n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.9415 - loss: 0.3356\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9506 - loss: 0.3034  \n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8814 - loss: 0.5155  \n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9015 - loss: 0.4444  \n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9198 - loss: 0.3734\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9311 - loss: 0.3472  \n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.4107 \n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9480 - loss: 0.2830  \n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168us/step - accuracy: 0.9208 - loss: 0.3598\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8989 - loss: 0.4290  \n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9131 - loss: 0.3786  \n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8898 - loss: 0.4719  \n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.3053 \n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9453 - loss: 0.2791  \n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9367 - loss: 0.3089 \n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9337 - loss: 0.3013  \n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.3778 \n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9521 - loss: 0.2365  \n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9278 - loss: 0.3379 \n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9024 - loss: 0.4309\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9209 - loss: 0.3427  \n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9315 - loss: 0.3070\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9324 - loss: 0.3052  \n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9268 - loss: 0.3376  \n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.2866 \n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.3358\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.3593 \n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9596 - loss: 0.2163  \n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251us/step - accuracy: 0.9311 - loss: 0.3106\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9246 - loss: 0.3201  \n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9315 - loss: 0.3143 \n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9041 - loss: 0.4065  \n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.2633 \n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9057 - loss: 0.4063  \n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9302 - loss: 0.3057  \n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9498 - loss: 0.2372  \n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9293 - loss: 0.3060 \n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.3476\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.4402 \n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9446 - loss: 0.2435  \n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9419 - loss: 0.2634 \n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9198 - loss: 0.3218  \n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9276 - loss: 0.3202 \n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9419 - loss: 0.2724  \n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.4108 \n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.9135 - loss: 0.3346\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9544 - loss: 0.2236  \n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9282 - loss: 0.3114  \n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.3724 \n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9414 - loss: 0.2671  \n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9230 - loss: 0.3285 \n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.3475 \n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9155 - loss: 0.3588  \n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9487 - loss: 0.2423 \n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9272 - loss: 0.3115  \n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.4183 \n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8981 - loss: 0.4162  \n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.3754 \n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176us/step - accuracy: 0.9054 - loss: 0.4161\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9383 - loss: 0.2656 \n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9332 - loss: 0.2803  \n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9245 - loss: 0.3451 \n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9106 - loss: 0.3932  \n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.2946 \n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.9441 - loss: 0.2554\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9015 - loss: 0.3789 \n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58us/step - accuracy: 0.9360 - loss: 0.2818\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9070 - loss: 0.3394  \n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9488 - loss: 0.2591  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8929 - loss: 0.5238\n",
      "Accuracy: 0.8928571343421936\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Function to safely evaluate a string representation of a list\n",
    "def safe_eval(x):\n",
    "    if isinstance(x, str):\n",
    "        return ast.literal_eval(x)\n",
    "    return x\n",
    "\n",
    "# Apply the safe_eval function to convert vector columns from string to list (if necessary)\n",
    "Rice_KG_df['source_vector'] = Rice_KG_df['source_vector'].apply(safe_eval)\n",
    "Rice_KG_df['target_vector'] = Rice_KG_df['target_vector'].apply(safe_eval)\n",
    "\n",
    "# Concatenate source and target vectors as features\n",
    "source_vectors = np.array(Rice_KG_df['source_vector'].tolist())\n",
    "target_vectors = np.array(Rice_KG_df['target_vector'].tolist())\n",
    "X = np.concatenate([source_vectors, target_vectors], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(Rice_KG_df['relationship_type'])\n",
    "\n",
    "# Reshape data for LSTM (samples, timesteps, features)\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Determine the number of unique classes\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(num_classes, activation='softmax')  # Output layer with softmax activation for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy for integer-encoded labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, rnn_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", rnn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the accuracy scores of four other models stored in variables\n",
    "\n",
    "# Define the model names\n",
    "model_names = ['Random Forest', 'Decision Tree', 'Neural Network', 'CNN', 'RNN']\n",
    "\n",
    "# Define the accuracy scores\n",
    "accuracy_scores = [rf_accuracy, dt_accuracy, nn_accuracy, cnn_accuracy, rnn_accuracy]\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, accuracy_scores, color=['blue', 'green', 'red', 'orange', 'purple'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Rice Knowledge Graph ML Model')\n",
    "plt.ylim(0, 1)  # Set the y-axis limits to ensure all bars are visible\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
