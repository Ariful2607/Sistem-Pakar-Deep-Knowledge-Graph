{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://34.101.192.24:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"unej1234\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_properties():\n",
    "    with driver.session() as session:\n",
    "        # Cypher query to fetch node properties\n",
    "        query = \"\"\"\n",
    "        MATCH (n)\n",
    "        RETURN n.Vector AS vector, n.label AS label, labels(n) AS kelas, n.abstract AS keterangan\n",
    "        \"\"\"\n",
    "        result = session.run(query)\n",
    "        # Extract properties and store in DataFrame\n",
    "        df = pd.DataFrame([record.values() for record in result], columns=result.keys())\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector</th>\n",
       "      <th>label</th>\n",
       "      <th>kelas</th>\n",
       "      <th>keterangan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.03639092668890953, -0.024370986968278885, -...</td>\n",
       "      <td>Metalaxyl</td>\n",
       "      <td>[Fungisida]</td>\n",
       "      <td>Metalaxyl adalah sejenis fungisida yang diguna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>Penyakit gosong bulir padi, juga dikenal sebag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.032646406441926956, -0.04352227970957756, 0...</td>\n",
       "      <td>Laba laba</td>\n",
       "      <td>[Biologis]</td>\n",
       "      <td>Laba-laba adalah predator umum yang dapat mema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.036355093121528625, 0.043446771800518036, 0...</td>\n",
       "      <td>Trichogramm</td>\n",
       "      <td>[Biologis]</td>\n",
       "      <td>Trichogramma atau parasitoid terkait hadir ada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.036346133798360825, -0.03959878906607628, -...</td>\n",
       "      <td>Acidovorax avenae subsp. avenae</td>\n",
       "      <td>[PatogenPadi]</td>\n",
       "      <td>Acidovorax avenae subsp. avenae adalah bakteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>[0.03919482231140137, -0.031110592186450958, 0...</td>\n",
       "      <td>Penggerek Batang Kuning</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "      <td>Penggerek batang kuning merupakan jenis serang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>[0.03915003314614296, -0.04633839428424835, 0....</td>\n",
       "      <td>Klorpiris</td>\n",
       "      <td>[Pestisida]</td>\n",
       "      <td>Klorpirifos adalah insektisida organofosfat. K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>[0.03914107382297516, -0.029383953660726547, -...</td>\n",
       "      <td>Rayap</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "      <td>Rayap dapat menyerang tanaman di semua tahap p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>[0.03916794806718826, 0.019752727821469307, 0....</td>\n",
       "      <td>Daun berkarat</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>Daun berkarat (pastula) berwarna kuning hingga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>[0.03915898874402046, 0.03670716658234596, -0....</td>\n",
       "      <td>Hawar Pelepah</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>Hawar pelepah padi adalah penyakit yang diseba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                vector  \\\n",
       "0    [0.03639092668890953, -0.024370986968278885, -...   \n",
       "1    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "2    [0.032646406441926956, -0.04352227970957756, 0...   \n",
       "3    [0.036355093121528625, 0.043446771800518036, 0...   \n",
       "4    [0.036346133798360825, -0.03959878906607628, -...   \n",
       "..                                                 ...   \n",
       "138  [0.03919482231140137, -0.031110592186450958, 0...   \n",
       "139  [0.03915003314614296, -0.04633839428424835, 0....   \n",
       "140  [0.03914107382297516, -0.029383953660726547, -...   \n",
       "141  [0.03916794806718826, 0.019752727821469307, 0....   \n",
       "142  [0.03915898874402046, 0.03670716658234596, -0....   \n",
       "\n",
       "                               label           kelas  \\\n",
       "0                          Metalaxyl     [Fungisida]   \n",
       "1                       Gosong bulir  [PenyakitPadi]   \n",
       "2                          Laba laba      [Biologis]   \n",
       "3                        Trichogramm      [Biologis]   \n",
       "4    Acidovorax avenae subsp. avenae   [PatogenPadi]   \n",
       "..                               ...             ...   \n",
       "138          Penggerek Batang Kuning      [HamaPadi]   \n",
       "139                        Klorpiris     [Pestisida]   \n",
       "140                            Rayap      [HamaPadi]   \n",
       "141                    Daun berkarat        [Gejala]   \n",
       "142                    Hawar Pelepah  [PenyakitPadi]   \n",
       "\n",
       "                                            keterangan  \n",
       "0    Metalaxyl adalah sejenis fungisida yang diguna...  \n",
       "1    Penyakit gosong bulir padi, juga dikenal sebag...  \n",
       "2    Laba-laba adalah predator umum yang dapat mema...  \n",
       "3    Trichogramma atau parasitoid terkait hadir ada...  \n",
       "4    Acidovorax avenae subsp. avenae adalah bakteri...  \n",
       "..                                                 ...  \n",
       "138  Penggerek batang kuning merupakan jenis serang...  \n",
       "139  Klorpirifos adalah insektisida organofosfat. K...  \n",
       "140  Rayap dapat menyerang tanaman di semua tahap p...  \n",
       "141  Daun berkarat (pastula) berwarna kuning hingga...  \n",
       "142  Hawar pelepah padi adalah penyakit yang diseba...  \n",
       "\n",
       "[143 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df = extract_node_properties()\n",
    "cleaned_kelas = node_df['kelas'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "node_df['kelas'] = cleaned_kelas\n",
    "node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_vector</th>\n",
       "      <th>source_label</th>\n",
       "      <th>source_class</th>\n",
       "      <th>relationship_type</th>\n",
       "      <th>target_vector</th>\n",
       "      <th>target_label</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03818255290389061, -0.015258912928402424, -...</td>\n",
       "      <td>Bulir terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03753756731748581, 0.005460740067064762, -0...</td>\n",
       "      <td>Bulir pecah</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03612148016691208, 0.0048484764993190765, 0...</td>\n",
       "      <td>Bulir berubah warna</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>terkenaPatogen</td>\n",
       "      <td>[0.03752860799431801, 0.022415179759263992, 0....</td>\n",
       "      <td>Tilletia barclayana</td>\n",
       "      <td>[PatogenPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>diberikanFungisida</td>\n",
       "      <td>[0.03760923072695732, -0.030174778774380684, 0...</td>\n",
       "      <td>Pyraclostrobin</td>\n",
       "      <td>[Fungisida]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>[0.03919482231140137, -0.031110592186450958, 0...</td>\n",
       "      <td>Penggerek Batang Kuning</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.038021307438611984, -0.010079000145196915, ...</td>\n",
       "      <td>Malai terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>[0.03919482231140137, -0.031110592186450958, 0...</td>\n",
       "      <td>Penggerek Batang Kuning</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.033894460648298264, -0.014245453290641308, ...</td>\n",
       "      <td>Daun terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>[0.03914107382297516, -0.029383953660726547, -...</td>\n",
       "      <td>Rayap</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03758235648274422, 0.02068854123353958, 0.0...</td>\n",
       "      <td>Batang rapuh</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>[0.03914107382297516, -0.029383953660726547, -...</td>\n",
       "      <td>Rayap</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03786005824804306, -0.004899086430668831, 0...</td>\n",
       "      <td>Akar berlubang</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>[0.03915898874402046, 0.03670716658234596, -0....</td>\n",
       "      <td>Hawar Pelepah</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03823630139231682, -0.01698555052280426, 0....</td>\n",
       "      <td>Pelepah mengalami kerusakan</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_vector  \\\n",
       "0    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "1    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "2    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "3    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "4    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "..                                                 ...   \n",
       "249  [0.03919482231140137, -0.031110592186450958, 0...   \n",
       "250  [0.03919482231140137, -0.031110592186450958, 0...   \n",
       "251  [0.03914107382297516, -0.029383953660726547, -...   \n",
       "252  [0.03914107382297516, -0.029383953660726547, -...   \n",
       "253  [0.03915898874402046, 0.03670716658234596, -0....   \n",
       "\n",
       "                source_label    source_class   relationship_type  \\\n",
       "0               Gosong bulir  [PenyakitPadi]      memilikiGejala   \n",
       "1               Gosong bulir  [PenyakitPadi]      memilikiGejala   \n",
       "2               Gosong bulir  [PenyakitPadi]      memilikiGejala   \n",
       "3               Gosong bulir  [PenyakitPadi]      terkenaPatogen   \n",
       "4               Gosong bulir  [PenyakitPadi]  diberikanFungisida   \n",
       "..                       ...             ...                 ...   \n",
       "249  Penggerek Batang Kuning      [HamaPadi]      memilikiGejala   \n",
       "250  Penggerek Batang Kuning      [HamaPadi]      memilikiGejala   \n",
       "251                    Rayap      [HamaPadi]      memilikiGejala   \n",
       "252                    Rayap      [HamaPadi]      memilikiGejala   \n",
       "253            Hawar Pelepah  [PenyakitPadi]      memilikiGejala   \n",
       "\n",
       "                                         target_vector  \\\n",
       "0    [0.03818255290389061, -0.015258912928402424, -...   \n",
       "1    [0.03753756731748581, 0.005460740067064762, -0...   \n",
       "2    [0.03612148016691208, 0.0048484764993190765, 0...   \n",
       "3    [0.03752860799431801, 0.022415179759263992, 0....   \n",
       "4    [0.03760923072695732, -0.030174778774380684, 0...   \n",
       "..                                                 ...   \n",
       "249  [0.038021307438611984, -0.010079000145196915, ...   \n",
       "250  [0.033894460648298264, -0.014245453290641308, ...   \n",
       "251  [0.03758235648274422, 0.02068854123353958, 0.0...   \n",
       "252  [0.03786005824804306, -0.004899086430668831, 0...   \n",
       "253  [0.03823630139231682, -0.01698555052280426, 0....   \n",
       "\n",
       "                    target_label   target_class  \n",
       "0          Bulir terdapat bercak       [Gejala]  \n",
       "1                    Bulir pecah       [Gejala]  \n",
       "2            Bulir berubah warna       [Gejala]  \n",
       "3            Tilletia barclayana  [PatogenPadi]  \n",
       "4                 Pyraclostrobin    [Fungisida]  \n",
       "..                           ...            ...  \n",
       "249        Malai terdapat bercak       [Gejala]  \n",
       "250         Daun terdapat bercak       [Gejala]  \n",
       "251                 Batang rapuh       [Gejala]  \n",
       "252               Akar berlubang       [Gejala]  \n",
       "253  Pelepah mengalami kerusakan       [Gejala]  \n",
       "\n",
       "[254 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_node_properties_and_relationships():\n",
    "    with driver.session() as session:\n",
    "        # Cypher query to fetch node properties and relationships\n",
    "        query = \"\"\"\n",
    "            MATCH (n)-[r]->(m)\n",
    "            RETURN n.Vector AS source_vector, n.label AS source_label, labels(n) AS source_class, \n",
    "                type(r) AS relationship_type,\n",
    "                m.Vector AS target_vector, m.label AS target_label, labels(m) AS target_class\n",
    "        \"\"\"\n",
    "        result = session.run(query)\n",
    "        # Extract properties and relationships and store in DataFrame\n",
    "        df = pd.DataFrame([record.values() for record in result], columns=result.keys())\n",
    "        # Clean labels\n",
    "        df['source_class'] = df['source_class'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "        df['target_class'] = df['target_class'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "        return df\n",
    "\n",
    "# Call the function to extract node properties and relationships\n",
    "Rice_KG_df = extract_node_properties_and_relationships()\n",
    "\n",
    "# Print the DataFrame\n",
    "Rice_KG_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_vector</th>\n",
       "      <th>source_label</th>\n",
       "      <th>source_class</th>\n",
       "      <th>relationship_type</th>\n",
       "      <th>target_vector</th>\n",
       "      <th>target_label</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03818255290389061, -0.015258912928402424, -...</td>\n",
       "      <td>Bulir terdapat bercak</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03753756731748581, 0.005460740067064762, -0...</td>\n",
       "      <td>Bulir pecah</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03612148016691208, 0.0048484764993190765, 0...</td>\n",
       "      <td>Bulir berubah warna</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03656195476651192, 0.02377898246049881, 0.0...</td>\n",
       "      <td>Bulir mengalami kerusakan</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.03643496334552765, -0.020186755806207657, -...</td>\n",
       "      <td>Garis Merah</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.038021307438611984, -0.010079000145196915, ...</td>\n",
       "      <td>Malai terdapat bercak</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>[0.03919482231140137, -0.031110592186450958, 0...</td>\n",
       "      <td>Penggerek Batang Kuning</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.038021307438611984, -0.010079000145196915, ...</td>\n",
       "      <td>Malai terdapat bercak</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>[0.03919482231140137, -0.031110592186450958, 0...</td>\n",
       "      <td>Penggerek Batang Kuning</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.033894460648298264, -0.014245453290641308, ...</td>\n",
       "      <td>Daun terdapat bercak</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>[0.03914107382297516, -0.029383953660726547, -...</td>\n",
       "      <td>Rayap</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03758235648274422, 0.02068854123353958, 0.0...</td>\n",
       "      <td>Batang rapuh</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>[0.03914107382297516, -0.029383953660726547, -...</td>\n",
       "      <td>Rayap</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03786005824804306, -0.004899086430668831, 0...</td>\n",
       "      <td>Akar berlubang</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>[0.03915898874402046, 0.03670716658234596, -0....</td>\n",
       "      <td>Hawar Pelepah</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03823630139231682, -0.01698555052280426, 0....</td>\n",
       "      <td>Pelepah mengalami kerusakan</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_vector  \\\n",
       "0    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "1    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "2    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "3    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "4    [0.03643496334552765, -0.020186755806207657, -...   \n",
       "..                                                 ...   \n",
       "131  [0.03919482231140137, -0.031110592186450958, 0...   \n",
       "132  [0.03919482231140137, -0.031110592186450958, 0...   \n",
       "133  [0.03914107382297516, -0.029383953660726547, -...   \n",
       "134  [0.03914107382297516, -0.029383953660726547, -...   \n",
       "135  [0.03915898874402046, 0.03670716658234596, -0....   \n",
       "\n",
       "                source_label source_class relationship_type  \\\n",
       "0               Gosong bulir     [Gejala]    memilikiGejala   \n",
       "1               Gosong bulir     [Gejala]    memilikiGejala   \n",
       "2               Gosong bulir     [Gejala]    memilikiGejala   \n",
       "3               Gosong bulir     [Gejala]    memilikiGejala   \n",
       "4                Garis Merah     [Gejala]    memilikiGejala   \n",
       "..                       ...          ...               ...   \n",
       "131  Penggerek Batang Kuning     [Gejala]    memilikiGejala   \n",
       "132  Penggerek Batang Kuning     [Gejala]    memilikiGejala   \n",
       "133                    Rayap     [Gejala]    memilikiGejala   \n",
       "134                    Rayap     [Gejala]    memilikiGejala   \n",
       "135            Hawar Pelepah     [Gejala]    memilikiGejala   \n",
       "\n",
       "                                         target_vector  \\\n",
       "0    [0.03818255290389061, -0.015258912928402424, -...   \n",
       "1    [0.03753756731748581, 0.005460740067064762, -0...   \n",
       "2    [0.03612148016691208, 0.0048484764993190765, 0...   \n",
       "3    [0.03656195476651192, 0.02377898246049881, 0.0...   \n",
       "4    [0.038021307438611984, -0.010079000145196915, ...   \n",
       "..                                                 ...   \n",
       "131  [0.038021307438611984, -0.010079000145196915, ...   \n",
       "132  [0.033894460648298264, -0.014245453290641308, ...   \n",
       "133  [0.03758235648274422, 0.02068854123353958, 0.0...   \n",
       "134  [0.03786005824804306, -0.004899086430668831, 0...   \n",
       "135  [0.03823630139231682, -0.01698555052280426, 0....   \n",
       "\n",
       "                    target_label    target_class  \n",
       "0          Bulir terdapat bercak  [PenyakitPadi]  \n",
       "1                    Bulir pecah  [PenyakitPadi]  \n",
       "2            Bulir berubah warna  [PenyakitPadi]  \n",
       "3      Bulir mengalami kerusakan  [PenyakitPadi]  \n",
       "4          Malai terdapat bercak  [PenyakitPadi]  \n",
       "..                           ...             ...  \n",
       "131        Malai terdapat bercak      [HamaPadi]  \n",
       "132         Daun terdapat bercak      [HamaPadi]  \n",
       "133                 Batang rapuh      [HamaPadi]  \n",
       "134               Akar berlubang      [HamaPadi]  \n",
       "135  Pelepah mengalami kerusakan  [PenyakitPadi]  \n",
       "\n",
       "[136 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_node_properties_and_relationships():\n",
    "    with driver.session() as session:\n",
    "        # Cypher query to fetch node properties and relationships\n",
    "        query = \"\"\"\n",
    "        MATCH (n)-[r]->(m)\n",
    "            WHERE any(label IN labels(n) WHERE label IN ['Gejala', 'PenyakitPadi', 'HamaPadi']) \n",
    "            AND any(label IN labels(m) WHERE label IN ['Gejala', 'PenyakitPadi', 'HamaPadi'])\n",
    "        RETURN \n",
    "        n.Vector AS source_vector, n.label AS source_label, labels(m) AS source_class, \n",
    "        type(r) AS relationship_type,\n",
    "        m.Vector AS target_vector, m.label AS target_label, labels(n) AS target_class\n",
    "\n",
    "        \"\"\"\n",
    "        result = session.run(query)\n",
    "        # Extract properties and relationships and store in DataFrame\n",
    "        df = pd.DataFrame([record.values() for record in result], columns=result.keys())\n",
    "        # Clean labels\n",
    "        df['source_class'] = df['source_class'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "        df['target_class'] = df['target_class'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "        return df\n",
    "\n",
    "# Call the function to extract node properties and relationships\n",
    "Rice_KG_df = extract_node_properties_and_relationships()\n",
    "\n",
    "# Print the DataFrame\n",
    "Rice_KG_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.89285714 0.92592593 0.92592593 0.88888889 0.92592593]\n",
      "Mean accuracy: 0.9119047619047619\n"
     ]
    }
   ],
   "source": [
    "###     RANDOM FOREST   ###\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert source and target vectors to numpy arrays\n",
    "source_vectors = np.array(Rice_KG_df['source_vector'].tolist())\n",
    "target_vectors = np.array(Rice_KG_df['target_vector'].tolist())\n",
    "\n",
    "# Concatenate source and target vectors as features\n",
    "X = np.concatenate([source_vectors, target_vectors], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(Rice_KG_df['relationship_type'])\n",
    "\n",
    "# Perform cross-validation\n",
    "rf_accuracy = cross_val_score(RandomForestClassifier(), X, y, cv=5)  # 5-fold cross-validation\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", rf_accuracy)\n",
    "print(\"Mean accuracy:\", np.mean(rf_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.89285714 0.85185185 0.85185185 0.62962963 0.85185185]\n",
      "Mean accuracy: 0.8156084656084657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "###     DECISION TREE   ###\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Convert source and target vectors to numpy arrays\n",
    "source_vectors = np.array(Rice_KG_df['source_vector'].tolist())\n",
    "target_vectors = np.array(Rice_KG_df['target_vector'].tolist())\n",
    "\n",
    "# Concatenate source and target vectors as features\n",
    "X = np.concatenate([source_vectors, target_vectors], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(Rice_KG_df['relationship_type'])\n",
    "\n",
    "# Perform cross-validation\n",
    "dt_accuracy = cross_val_score(DecisionTreeClassifier(), X, y, cv=5)  # 5-fold cross-validation\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", dt_accuracy)\n",
    "print(\"Mean accuracy:\", np.mean(dt_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2077 - loss: 1.7916      \n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9298 - loss: 1.7429  \n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9267 - loss: 1.6897  \n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 1.6217 \n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9202 - loss: 1.5326  \n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9032 - loss: 1.4200  \n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9498 - loss: 1.2470  \n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 1.0788 \n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8998 - loss: 0.9094 \n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9278 - loss: 0.6859  \n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9200 - loss: 0.5410  \n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.4632 \n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9146 - loss: 0.4168  \n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9255 - loss: 0.3831  \n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9543 - loss: 0.2451 \n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.2511\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.3332 \n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9457 - loss: 0.2729  \n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9255 - loss: 0.3281  \n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9080 - loss: 0.3996  \n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9317 - loss: 0.3223 \n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8889 - loss: 0.4659  \n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.2412 \n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9136 - loss: 0.3631  \n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9092 - loss: 0.3728  \n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9320 - loss: 0.2846 \n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9317 - loss: 0.3216  \n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9259 - loss: 0.3379  \n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.3609 \n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9343 - loss: 0.2758  \n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9548 - loss: 0.2113  \n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9297 - loss: 0.3409 \n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9067 - loss: 0.3805  \n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9315 - loss: 0.2754 \n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8924 - loss: 0.4340  \n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9113 - loss: 0.3617  \n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9218 - loss: 0.2994  \n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9131 - loss: 0.3183  \n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.3551 \n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.3281 \n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9518 - loss: 0.2121  \n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step - accuracy: 0.9298 - loss: 0.3045\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1994 \n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9379 - loss: 0.2244 \n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.2009 \n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9521 - loss: 0.1796  \n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9106 - loss: 0.3339  \n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.3443 \n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.9252 - loss: 0.2750\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1791 \n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8944 - loss: 0.3707  \n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9013 - loss: 0.3099 \n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9031 - loss: 0.3294  \n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8961 - loss: 0.3421 \n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.9548 - loss: 0.1814\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.2075 \n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.9316 - loss: 0.2184\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.9006 - loss: 0.2633\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.1985 \n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2656 \n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9405 - loss: 0.2061  \n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9256 - loss: 0.2375  \n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.1942 \n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9344 - loss: 0.2743  \n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9256 - loss: 0.2816 \n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9506 - loss: 0.2184  \n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9610 - loss: 0.1586 \n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9392 - loss: 0.2066  \n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.2452 \n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9582 - loss: 0.1770  \n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9541 - loss: 0.1999  \n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.9425 - loss: 0.2120\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9386 - loss: 0.2531  \n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9775 - loss: 0.1269 \n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9610 - loss: 0.1524  \n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9668 - loss: 0.1558 \n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9438 - loss: 0.2000  \n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9544 - loss: 0.1850 \n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.1944 \n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74us/step - accuracy: 0.9340 - loss: 0.2023\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.1684 \n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9701 - loss: 0.1258  \n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.2013 \n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9610 - loss: 0.1317  \n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9431 - loss: 0.2353 \n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step - accuracy: 0.9555 - loss: 0.1787\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9681 - loss: 0.1452  \n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step - accuracy: 0.9766 - loss: 0.1194\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9464 - loss: 0.2060  \n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9487 - loss: 0.1653 \n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9548 - loss: 0.1764  \n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280us/step - accuracy: 0.9705 - loss: 0.1160\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9487 - loss: 0.1571  \n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.9768 - loss: 0.1150\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9494 - loss: 0.1635  \n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9557 - loss: 0.1664 \n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9620 - loss: 0.1210  \n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.2052 \n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9718 - loss: 0.1057  \n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53us/step - accuracy: 0.9574 - loss: 0.1201\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8929 - loss: 0.6282\n",
      "Accuracy: 0.8928571343421936\n"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Concatenate source and target vectors as features\n",
    "X = np.concatenate([Rice_KG_df['source_vector'].values.tolist(), Rice_KG_df['target_vector'].values.tolist()], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(Rice_KG_df['relationship_type'])\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax') # Output layer with softmax activation for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # Use sparse categorical crossentropy for integer-encoded labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, nn_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", nn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5915 - loss: 1.7725  \n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 1.6852 \n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9397 - loss: 1.4964 \n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 1.1973 \n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9289 - loss: 0.7399  \n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.9028 - loss: 0.4860\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273us/step - accuracy: 0.9104 - loss: 0.5475\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.9265 - loss: 0.3652\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9388 - loss: 0.3511 \n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9278 - loss: 0.4061 \n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.3041 \n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9479 - loss: 0.2858 \n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9535 - loss: 0.3128 \n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.5280 \n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - accuracy: 0.9405 - loss: 0.3280\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - accuracy: 0.9139 - loss: 0.4493\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.9476 - loss: 0.3033\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.3665 \n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9268 - loss: 0.3905 \n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.3630 \n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.4934 \n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9054 - loss: 0.4070 \n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 0.3104 \n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9340 - loss: 0.3827 \n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.4173 \n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.3132 \n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9356 - loss: 0.3243 \n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9332 - loss: 0.3632 \n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.3172 \n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.3269 \n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9327 - loss: 0.3369 \n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.3734 \n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.3380 \n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.4270 \n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.3984 \n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9592 - loss: 0.2159 \n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9162 - loss: 0.4227  \n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9319 - loss: 0.3062 \n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.9067 - loss: 0.4603\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9246 - loss: 0.3973\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9446 - loss: 0.2788  \n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.9437 - loss: 0.3491\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190us/step - accuracy: 0.9213 - loss: 0.3646\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8961 - loss: 0.4368  \n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step - accuracy: 0.9087 - loss: 0.4869\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9393 - loss: 0.3412 \n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.3713 \n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9079 - loss: 0.3704  \n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9234 - loss: 0.3858  \n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.9431 - loss: 0.2991\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.3488 \n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9493 - loss: 0.2653 \n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9385 - loss: 0.3179 \n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.5233 \n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9248 - loss: 0.3894 \n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8931 - loss: 0.4885  \n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.8996 - loss: 0.4443\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.9217 - loss: 0.3633\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9513 - loss: 0.2692 \n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9304 - loss: 0.3038 \n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9231 - loss: 0.3483 \n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.4348 \n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9172 - loss: 0.3828 \n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.2661 \n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9291 - loss: 0.3778 \n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9103 - loss: 0.4060 \n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9506 - loss: 0.3030 \n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.9385 - loss: 0.3215\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.9459 - loss: 0.2751\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9314 - loss: 0.3799 \n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.4478 \n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.3165 \n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9508 - loss: 0.3290 \n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9346 - loss: 0.3113  \n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.9278 - loss: 0.3528\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.2604 \n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9324 - loss: 0.3583 \n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9424 - loss: 0.3225 \n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9093 - loss: 0.4160 \n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.3817 \n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.3492 \n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9360 - loss: 0.3532 \n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9217 - loss: 0.3884 \n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - accuracy: 0.9011 - loss: 0.4411\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.9294 - loss: 0.3607\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.9461 - loss: 0.2654\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.3731 \n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.4048 \n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9289 - loss: 0.3932 \n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9383 - loss: 0.3155  \n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9298 - loss: 0.2895\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.9424 - loss: 0.2854\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.4078 \n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9396 - loss: 0.2974 \n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9386 - loss: 0.3313 \n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.3874 \n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9363 - loss: 0.3675 \n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.3994 \n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8879 - loss: 0.5069 \n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.2948 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.8929 - loss: 0.6366\n",
      "Accuracy: 0.8928571343421936\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "\n",
    "# Reshape the input data to be suitable for a 1D CNN\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(64, 3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(32, 3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(np.unique(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # Use sparse categorical crossentropy for integer-encoded labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, cnn_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", cnn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0s/step - accuracy: 0.5201 - loss: 1.7866\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9381 - loss: 1.7628 \n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9332 - loss: 1.7379  \n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9443 - loss: 1.7098 \n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9545 - loss: 1.6782  \n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9473 - loss: 1.6455 \n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9381 - loss: 1.6097  \n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9376 - loss: 1.5688 \n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9537 - loss: 1.5199  \n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 1.4716 \n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9530 - loss: 1.4163  \n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9751 - loss: 1.3487 \n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9641 - loss: 1.2862  \n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 1.2527 \n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9522 - loss: 1.1695  \n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9606 - loss: 1.0885 \n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 1.0147 \n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9589 - loss: 0.9491  \n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9495 - loss: 0.8895  \n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9217 - loss: 0.8638  \n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9195 - loss: 0.7978 \n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9751 - loss: 0.6521  \n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 0.6509 \n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9588 - loss: 0.5652  \n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.5135 \n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9443 - loss: 0.5084  \n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.4294 \n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113us/step - accuracy: 0.9558 - loss: 0.4131\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.3932 \n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9406 - loss: 0.4030  \n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9637 - loss: 0.3211  \n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9548 - loss: 0.3249  \n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9240 - loss: 0.3972  \n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20us/step - accuracy: 0.9577 - loss: 0.2909\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9269 - loss: 0.3718  \n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9500 - loss: 0.2972  \n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9433 - loss: 0.3121  \n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9751 - loss: 0.2031  \n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9466 - loss: 0.2948  \n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58us/step - accuracy: 0.9492 - loss: 0.2773\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9202 - loss: 0.3728  \n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.9257 - loss: 0.3508\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9513 - loss: 0.2482  \n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.3745 \n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9589 - loss: 0.2247 \n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9470 - loss: 0.2624\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9681 - loss: 0.1850  \n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.2257 \n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9735 - loss: 0.1614  \n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9332 - loss: 0.2962 \n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9588 - loss: 0.2026  \n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9418 - loss: 0.2635 \n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9664 - loss: 0.1834  \n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9734 - loss: 0.1564\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9287 - loss: 0.3062  \n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9670 - loss: 0.1816  \n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9455 - loss: 0.2462  \n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.9463 - loss: 0.2370\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9388 - loss: 0.2667 \n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9588 - loss: 0.1871  \n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9681 - loss: 0.1647 \n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114us/step - accuracy: 0.9533 - loss: 0.2062\n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9481 - loss: 0.2294  \n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9619 - loss: 0.1890  \n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.2573 \n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9711 - loss: 0.1511  \n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2924 \n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9589 - loss: 0.1931  \n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.2465 \n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.2909 \n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9411 - loss: 0.2520 \n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9329 - loss: 0.2796  \n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9403 - loss: 0.2552 \n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9637 - loss: 0.1666  \n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1941 \n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.9533 - loss: 0.2063\n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 0.2441 \n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9433 - loss: 0.2339  \n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.9533 - loss: 0.2056\n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9376 - loss: 0.2565 \n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9403 - loss: 0.2466  \n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9384 - loss: 0.2637 \n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9173 - loss: 0.3093  \n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9562 - loss: 0.1897 \n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9478 - loss: 0.2289  \n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.1611 \n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9247 - loss: 0.2908  \n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.2130 \n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9495 - loss: 0.2043  \n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9473 - loss: 0.2206\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9548 - loss: 0.2009 \n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9123 - loss: 0.3107  \n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9463 - loss: 0.2095  \n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9376 - loss: 0.2283  \n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178us/step - accuracy: 0.9443 - loss: 0.2101\n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1837 \n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.2065 \n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.2121 \n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9533 - loss: 0.1905 \n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9588 - loss: 0.1626  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8608 - loss: 0.7695   \n",
      "Accuracy: 0.8536585569381714\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Function to safely evaluate a string representation of a list\n",
    "def safe_eval(x):\n",
    "    if isinstance(x, str):\n",
    "        return ast.literal_eval(x)\n",
    "    return x\n",
    "\n",
    "# Apply the safe_eval function to convert vector columns from string to list (if necessary)\n",
    "Rice_KG_df['source_vector'] = Rice_KG_df['source_vector'].apply(safe_eval)\n",
    "Rice_KG_df['target_vector'] = Rice_KG_df['target_vector'].apply(safe_eval)\n",
    "\n",
    "# Concatenate source and target vectors as features\n",
    "source_vectors = np.array(Rice_KG_df['source_vector'].tolist())\n",
    "target_vectors = np.array(Rice_KG_df['target_vector'].tolist())\n",
    "X = np.concatenate([source_vectors, target_vectors], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(Rice_KG_df['relationship_type'])\n",
    "\n",
    "# Reshape data for LSTM (samples, timesteps, features)\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Determine the number of unique classes\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(num_classes, activation='softmax')  # Output layer with softmax activation for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy for integer-encoded labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, rnn_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", rnn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the accuracy scores of four other models stored in variables\n",
    "\n",
    "# Define the model names\n",
    "model_names = ['Random Forest', 'Decision Tree', 'Neural Network', 'CNN', 'RNN']\n",
    "\n",
    "# Define the accuracy scores\n",
    "accuracy_scores = [np.mean(rf_accuracy), np.mean(dt_accuracy), nn_accuracy, cnn_accuracy, rnn_accuracy]\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, accuracy_scores, color=['blue', 'green', 'red', 'orange', 'purple'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Rice Knowledge Graph with ML/DL Model')\n",
    "plt.ylim(0, 1)  # Set the y-axis limits to ensure all bars are visible\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
