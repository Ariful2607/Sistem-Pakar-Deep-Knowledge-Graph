{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://34.128.111.121:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"unej1234\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_properties():\n",
    "    with driver.session() as session:\n",
    "        # Cypher query to fetch node properties\n",
    "        query = \"\"\"\n",
    "        MATCH (n)\n",
    "        RETURN n.Vector AS vector, n.label AS label, labels(n) AS kelas, n.abstract AS keterangan\n",
    "        \"\"\"\n",
    "        result = session.run(query)\n",
    "        # Extract properties and store in DataFrame\n",
    "        df = pd.DataFrame([record.values() for record in result], columns=result.keys())\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector</th>\n",
       "      <th>label</th>\n",
       "      <th>kelas</th>\n",
       "      <th>keterangan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.08210227638483047, -1.196730375289917, 0.4...</td>\n",
       "      <td>Metalaxyl</td>\n",
       "      <td>[Fungisida]</td>\n",
       "      <td>Metalaxyl adalah sejenis fungisida yang diguna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.07298001646995544, -1.2374435663223267, 0.7...</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>Penyakit gosong bulir padi, juga dikenal sebag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.17221221327781677, -0.11851631850004196, -...</td>\n",
       "      <td>Acidovorax avenae subsp. avenae</td>\n",
       "      <td>[PatogenPadi]</td>\n",
       "      <td>Acidovorax avenae subsp. avenae adalah bakteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.09642044454813004, -0.09432632476091385, -0...</td>\n",
       "      <td>Tanaman layu</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>Gejala layu pada tanaman padi adalah tanda yan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.028699690476059914, -0.9930149912834167, -...</td>\n",
       "      <td>Bibit mati</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>Gejala kematian bibit padi dapat terlihat dala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>[0.06340976804494858, -0.9591665863990784, -1....</td>\n",
       "      <td>Bacillus thuringiensis var. israelensis</td>\n",
       "      <td>[Pestisida]</td>\n",
       "      <td>Bacillus thuringiensis var. israelensis (Bti) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>[0.26280516386032104, 0.8804101943969727, 0.96...</td>\n",
       "      <td>Belalang Sawah</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "      <td>Belalang sawah, atau Nilaparvata lugens, adala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>[0.5597228407859802, 0.4738956689834595, -0.00...</td>\n",
       "      <td>Bakteri Garis Daun</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>Penyakit bakteri garis daun pada padi disebabk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>[0.22912395000457764, -0.31869229674339294, -0...</td>\n",
       "      <td>Fusarium spp.</td>\n",
       "      <td>[PatogenPadi]</td>\n",
       "      <td>Fusarium spp. adalah kelompok jamur patogen ya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>[0.2573350965976715, 0.5282686948776245, -0.23...</td>\n",
       "      <td>Daun berkarat</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>Daun berkarat (pastula) berwarna kuning hingga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                vector  \\\n",
       "0    [-0.08210227638483047, -1.196730375289917, 0.4...   \n",
       "1    [0.07298001646995544, -1.2374435663223267, 0.7...   \n",
       "2    [-0.17221221327781677, -0.11851631850004196, -...   \n",
       "3    [0.09642044454813004, -0.09432632476091385, -0...   \n",
       "4    [-0.028699690476059914, -0.9930149912834167, -...   \n",
       "..                                                 ...   \n",
       "111  [0.06340976804494858, -0.9591665863990784, -1....   \n",
       "112  [0.26280516386032104, 0.8804101943969727, 0.96...   \n",
       "113  [0.5597228407859802, 0.4738956689834595, -0.00...   \n",
       "114  [0.22912395000457764, -0.31869229674339294, -0...   \n",
       "115  [0.2573350965976715, 0.5282686948776245, -0.23...   \n",
       "\n",
       "                                       label           kelas  \\\n",
       "0                                  Metalaxyl     [Fungisida]   \n",
       "1                               Gosong bulir  [PenyakitPadi]   \n",
       "2            Acidovorax avenae subsp. avenae   [PatogenPadi]   \n",
       "3                               Tanaman layu        [Gejala]   \n",
       "4                                 Bibit mati        [Gejala]   \n",
       "..                                       ...             ...   \n",
       "111  Bacillus thuringiensis var. israelensis     [Pestisida]   \n",
       "112                           Belalang Sawah      [HamaPadi]   \n",
       "113                       Bakteri Garis Daun  [PenyakitPadi]   \n",
       "114                            Fusarium spp.   [PatogenPadi]   \n",
       "115                            Daun berkarat        [Gejala]   \n",
       "\n",
       "                                            keterangan  \n",
       "0    Metalaxyl adalah sejenis fungisida yang diguna...  \n",
       "1    Penyakit gosong bulir padi, juga dikenal sebag...  \n",
       "2    Acidovorax avenae subsp. avenae adalah bakteri...  \n",
       "3    Gejala layu pada tanaman padi adalah tanda yan...  \n",
       "4    Gejala kematian bibit padi dapat terlihat dala...  \n",
       "..                                                 ...  \n",
       "111  Bacillus thuringiensis var. israelensis (Bti) ...  \n",
       "112  Belalang sawah, atau Nilaparvata lugens, adala...  \n",
       "113  Penyakit bakteri garis daun pada padi disebabk...  \n",
       "114  Fusarium spp. adalah kelompok jamur patogen ya...  \n",
       "115  Daun berkarat (pastula) berwarna kuning hingga...  \n",
       "\n",
       "[116 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df = extract_node_properties()\n",
    "cleaned_kelas = node_df['kelas'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "node_df['kelas'] = cleaned_kelas\n",
    "node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_vector</th>\n",
       "      <th>source_label</th>\n",
       "      <th>source_class</th>\n",
       "      <th>relationship_type</th>\n",
       "      <th>target_vector</th>\n",
       "      <th>target_label</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.07298001646995544, -1.2374435663223267, 0.7...</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03470959886908531, -1.1857260465621948, 0.8...</td>\n",
       "      <td>Bulir pecah</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.07298001646995544, -1.2374435663223267, 0.7...</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.13574755191802979, -1.3793666362762451, 1.0...</td>\n",
       "      <td>Bulir terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.07298001646995544, -1.2374435663223267, 0.7...</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>terkenaPatogen</td>\n",
       "      <td>[0.06818187981843948, -1.526533842086792, 0.76...</td>\n",
       "      <td>Tilletia barclayana</td>\n",
       "      <td>[PatogenPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.07298001646995544, -1.2374435663223267, 0.7...</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[-0.10305600613355637, -0.9914171099662781, 0....</td>\n",
       "      <td>Bulir berubah warna</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.07298001646995544, -1.2374435663223267, 0.7...</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.08502250909805298, -1.3067476749420166, 0.5...</td>\n",
       "      <td>Bulir mengalami kerusakan</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>[0.5597228407859802, 0.4738956689834595, -0.00...</td>\n",
       "      <td>Bakteri Garis Daun</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>terkenaPatogen</td>\n",
       "      <td>[0.66168212890625, 0.46271994709968567, 0.3153...</td>\n",
       "      <td>Xanthomonas oryzae pv. oryzicola</td>\n",
       "      <td>[PatogenPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>[0.5597228407859802, 0.4738956689834595, -0.00...</td>\n",
       "      <td>Bakteri Garis Daun</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.15162724256515503, -0.20435462892055511, 0....</td>\n",
       "      <td>Malai mengalami kerusakan</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>[0.5597228407859802, 0.4738956689834595, -0.00...</td>\n",
       "      <td>Bakteri Garis Daun</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.3585258722305298, 0.6639047861099243, 0.411...</td>\n",
       "      <td>Daun menguning</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>[0.5597228407859802, 0.4738956689834595, -0.00...</td>\n",
       "      <td>Bakteri Garis Daun</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03997558727860451, 0.41051343083381653, -0....</td>\n",
       "      <td>Daun terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>[0.5597228407859802, 0.4738956689834595, -0.00...</td>\n",
       "      <td>Bakteri Garis Daun</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.16302461922168732, -0.14563263952732086, 0....</td>\n",
       "      <td>Daun mengering</td>\n",
       "      <td>[Gejala]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_vector        source_label  \\\n",
       "0    [0.07298001646995544, -1.2374435663223267, 0.7...        Gosong bulir   \n",
       "1    [0.07298001646995544, -1.2374435663223267, 0.7...        Gosong bulir   \n",
       "2    [0.07298001646995544, -1.2374435663223267, 0.7...        Gosong bulir   \n",
       "3    [0.07298001646995544, -1.2374435663223267, 0.7...        Gosong bulir   \n",
       "4    [0.07298001646995544, -1.2374435663223267, 0.7...        Gosong bulir   \n",
       "..                                                 ...                 ...   \n",
       "162  [0.5597228407859802, 0.4738956689834595, -0.00...  Bakteri Garis Daun   \n",
       "163  [0.5597228407859802, 0.4738956689834595, -0.00...  Bakteri Garis Daun   \n",
       "164  [0.5597228407859802, 0.4738956689834595, -0.00...  Bakteri Garis Daun   \n",
       "165  [0.5597228407859802, 0.4738956689834595, -0.00...  Bakteri Garis Daun   \n",
       "166  [0.5597228407859802, 0.4738956689834595, -0.00...  Bakteri Garis Daun   \n",
       "\n",
       "       source_class relationship_type  \\\n",
       "0    [PenyakitPadi]    memilikiGejala   \n",
       "1    [PenyakitPadi]    memilikiGejala   \n",
       "2    [PenyakitPadi]    terkenaPatogen   \n",
       "3    [PenyakitPadi]    memilikiGejala   \n",
       "4    [PenyakitPadi]    memilikiGejala   \n",
       "..              ...               ...   \n",
       "162  [PenyakitPadi]    terkenaPatogen   \n",
       "163  [PenyakitPadi]    memilikiGejala   \n",
       "164  [PenyakitPadi]    memilikiGejala   \n",
       "165  [PenyakitPadi]    memilikiGejala   \n",
       "166  [PenyakitPadi]    memilikiGejala   \n",
       "\n",
       "                                         target_vector  \\\n",
       "0    [0.03470959886908531, -1.1857260465621948, 0.8...   \n",
       "1    [0.13574755191802979, -1.3793666362762451, 1.0...   \n",
       "2    [0.06818187981843948, -1.526533842086792, 0.76...   \n",
       "3    [-0.10305600613355637, -0.9914171099662781, 0....   \n",
       "4    [0.08502250909805298, -1.3067476749420166, 0.5...   \n",
       "..                                                 ...   \n",
       "162  [0.66168212890625, 0.46271994709968567, 0.3153...   \n",
       "163  [0.15162724256515503, -0.20435462892055511, 0....   \n",
       "164  [0.3585258722305298, 0.6639047861099243, 0.411...   \n",
       "165  [0.03997558727860451, 0.41051343083381653, -0....   \n",
       "166  [0.16302461922168732, -0.14563263952732086, 0....   \n",
       "\n",
       "                         target_label   target_class  \n",
       "0                         Bulir pecah       [Gejala]  \n",
       "1               Bulir terdapat bercak       [Gejala]  \n",
       "2                 Tilletia barclayana  [PatogenPadi]  \n",
       "3                 Bulir berubah warna       [Gejala]  \n",
       "4           Bulir mengalami kerusakan       [Gejala]  \n",
       "..                                ...            ...  \n",
       "162  Xanthomonas oryzae pv. oryzicola  [PatogenPadi]  \n",
       "163         Malai mengalami kerusakan       [Gejala]  \n",
       "164                    Daun menguning       [Gejala]  \n",
       "165              Daun terdapat bercak       [Gejala]  \n",
       "166                    Daun mengering       [Gejala]  \n",
       "\n",
       "[167 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_node_properties_and_relationships():\n",
    "    with driver.session() as session:\n",
    "        # Cypher query to fetch node properties and relationships\n",
    "        query = \"\"\"\n",
    "            MATCH (n)-[r]->(m)\n",
    "            RETURN n.Vector AS source_vector, n.label AS source_label, labels(n) AS source_class, \n",
    "                type(r) AS relationship_type,\n",
    "                m.Vector AS target_vector, m.label AS target_label, labels(m) AS target_class\n",
    "        \"\"\"\n",
    "        result = session.run(query)\n",
    "        # Extract properties and relationships and store in DataFrame\n",
    "        df = pd.DataFrame([record.values() for record in result], columns=result.keys())\n",
    "        # Clean labels\n",
    "        df['source_class'] = df['source_class'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "        df['target_class'] = df['target_class'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "        return df\n",
    "\n",
    "# Call the function to extract node properties and relationships\n",
    "Rice_KG_df = extract_node_properties_and_relationships()\n",
    "\n",
    "# Print the DataFrame\n",
    "Rice_KG_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_vector</th>\n",
       "      <th>source_label</th>\n",
       "      <th>source_class</th>\n",
       "      <th>relationship_type</th>\n",
       "      <th>target_vector</th>\n",
       "      <th>target_label</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.03470959886908531, -1.1857260465621948, 0.8...</td>\n",
       "      <td>Bulir pecah</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.07298001646995544, -1.2374435663223267, 0.7...</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.13574755191802979, -1.3793666362762451, 1.0...</td>\n",
       "      <td>Bulir terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.07298001646995544, -1.2374435663223267, 0.7...</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.10305600613355637, -0.9914171099662781, 0....</td>\n",
       "      <td>Bulir berubah warna</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.07298001646995544, -1.2374435663223267, 0.7...</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.08502250909805298, -1.3067476749420166, 0.5...</td>\n",
       "      <td>Bulir mengalami kerusakan</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.07298001646995544, -1.2374435663223267, 0.7...</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.4479781985282898, 0.31867894530296326, 0.02...</td>\n",
       "      <td>Daun terdapat garis</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[-0.00347538897767663, 0.01217570248991251, -0...</td>\n",
       "      <td>Garis Merah</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>[-0.1632845550775528, -0.05104042589664459, 0....</td>\n",
       "      <td>Batang mengalami kerusakan</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.5597228407859802, 0.4738956689834595, -0.00...</td>\n",
       "      <td>Bakteri Garis Daun</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>[0.15162724256515503, -0.20435462892055511, 0....</td>\n",
       "      <td>Malai mengalami kerusakan</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.5597228407859802, 0.4738956689834595, -0.00...</td>\n",
       "      <td>Bakteri Garis Daun</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>[0.3585258722305298, 0.6639047861099243, 0.411...</td>\n",
       "      <td>Daun menguning</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.5597228407859802, 0.4738956689834595, -0.00...</td>\n",
       "      <td>Bakteri Garis Daun</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>[0.03997558727860451, 0.41051343083381653, -0....</td>\n",
       "      <td>Daun terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.5597228407859802, 0.4738956689834595, -0.00...</td>\n",
       "      <td>Bakteri Garis Daun</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>[0.16302461922168732, -0.14563263952732086, 0....</td>\n",
       "      <td>Daun mengering</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.5597228407859802, 0.4738956689834595, -0.00...</td>\n",
       "      <td>Bakteri Garis Daun</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        source_vector  \\\n",
       "0   [0.03470959886908531, -1.1857260465621948, 0.8...   \n",
       "1   [0.13574755191802979, -1.3793666362762451, 1.0...   \n",
       "2   [-0.10305600613355637, -0.9914171099662781, 0....   \n",
       "3   [0.08502250909805298, -1.3067476749420166, 0.5...   \n",
       "4   [0.4479781985282898, 0.31867894530296326, 0.02...   \n",
       "..                                                ...   \n",
       "79  [-0.1632845550775528, -0.05104042589664459, 0....   \n",
       "80  [0.15162724256515503, -0.20435462892055511, 0....   \n",
       "81  [0.3585258722305298, 0.6639047861099243, 0.411...   \n",
       "82  [0.03997558727860451, 0.41051343083381653, -0....   \n",
       "83  [0.16302461922168732, -0.14563263952732086, 0....   \n",
       "\n",
       "                  source_label source_class relationship_type  \\\n",
       "0                  Bulir pecah     [Gejala]    memilikiGejala   \n",
       "1        Bulir terdapat bercak     [Gejala]    memilikiGejala   \n",
       "2          Bulir berubah warna     [Gejala]    memilikiGejala   \n",
       "3    Bulir mengalami kerusakan     [Gejala]    memilikiGejala   \n",
       "4          Daun terdapat garis     [Gejala]    memilikiGejala   \n",
       "..                         ...          ...               ...   \n",
       "79  Batang mengalami kerusakan     [Gejala]    memilikiGejala   \n",
       "80   Malai mengalami kerusakan     [Gejala]    memilikiGejala   \n",
       "81              Daun menguning     [Gejala]    memilikiGejala   \n",
       "82        Daun terdapat bercak     [Gejala]    memilikiGejala   \n",
       "83              Daun mengering     [Gejala]    memilikiGejala   \n",
       "\n",
       "                                        target_vector        target_label  \\\n",
       "0   [0.07298001646995544, -1.2374435663223267, 0.7...        Gosong bulir   \n",
       "1   [0.07298001646995544, -1.2374435663223267, 0.7...        Gosong bulir   \n",
       "2   [0.07298001646995544, -1.2374435663223267, 0.7...        Gosong bulir   \n",
       "3   [0.07298001646995544, -1.2374435663223267, 0.7...        Gosong bulir   \n",
       "4   [-0.00347538897767663, 0.01217570248991251, -0...         Garis Merah   \n",
       "..                                                ...                 ...   \n",
       "79  [0.5597228407859802, 0.4738956689834595, -0.00...  Bakteri Garis Daun   \n",
       "80  [0.5597228407859802, 0.4738956689834595, -0.00...  Bakteri Garis Daun   \n",
       "81  [0.5597228407859802, 0.4738956689834595, -0.00...  Bakteri Garis Daun   \n",
       "82  [0.5597228407859802, 0.4738956689834595, -0.00...  Bakteri Garis Daun   \n",
       "83  [0.5597228407859802, 0.4738956689834595, -0.00...  Bakteri Garis Daun   \n",
       "\n",
       "      target_class  \n",
       "0   [PenyakitPadi]  \n",
       "1   [PenyakitPadi]  \n",
       "2   [PenyakitPadi]  \n",
       "3   [PenyakitPadi]  \n",
       "4   [PenyakitPadi]  \n",
       "..             ...  \n",
       "79  [PenyakitPadi]  \n",
       "80  [PenyakitPadi]  \n",
       "81  [PenyakitPadi]  \n",
       "82  [PenyakitPadi]  \n",
       "83  [PenyakitPadi]  \n",
       "\n",
       "[84 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_node_properties_and_relationships():\n",
    "    with driver.session() as session:\n",
    "        # Cypher query to fetch node properties and relationships\n",
    "        query = \"\"\"\n",
    "        MATCH (n)-[r]->(m)\n",
    "            WHERE any(label IN labels(n) WHERE label IN ['Gejala', 'PenyakitPadi', 'HamaPadi']) \n",
    "            AND any(label IN labels(m) WHERE label IN ['Gejala', 'PenyakitPadi', 'HamaPadi'])\n",
    "        RETURN \n",
    "        m.Vector AS source_vector, m.label AS source_label, labels(m) AS source_class, \n",
    "        type(r) AS relationship_type,\n",
    "        n.Vector AS target_vector, n.label AS target_label, labels(n) AS target_class\n",
    "\n",
    "        \"\"\"\n",
    "        result = session.run(query)\n",
    "        # Extract properties and relationships and store in DataFrame\n",
    "        df = pd.DataFrame([record.values() for record in result], columns=result.keys())\n",
    "        # Clean labels\n",
    "        df['source_class'] = df['source_class'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "        df['target_class'] = df['target_class'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "        return df\n",
    "\n",
    "# Call the function to extract node properties and relationships\n",
    "Rice_KG_df = extract_node_properties_and_relationships()\n",
    "\n",
    "# Print the DataFrame\n",
    "Rice_KG_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.88235294 0.88235294 0.88235294 0.94117647 0.8125    ]\n",
      "Mean accuracy: 0.8801470588235294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "###     RANDOM FOREST   ###\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert source and target vectors to numpy arrays\n",
    "source_vectors = np.array(Rice_KG_df['source_vector'].tolist())\n",
    "target_vectors = np.array(Rice_KG_df['target_vector'].tolist())\n",
    "\n",
    "# Concatenate source and target vectors as features\n",
    "X = np.concatenate([source_vectors, target_vectors], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(Rice_KG_df['relationship_type'])\n",
    "\n",
    "# Perform cross-validation\n",
    "rf_accuracy = cross_val_score(RandomForestClassifier(), X, y, cv=5)  # 5-fold cross-validation\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", rf_accuracy)\n",
    "print(\"Mean accuracy:\", np.mean(rf_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.82352941 0.94117647 0.64705882 0.94117647 0.8125    ]\n",
      "Mean accuracy: 0.8330882352941176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "###     DECISION TREE   ###\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Convert source and target vectors to numpy arrays\n",
    "source_vectors = np.array(Rice_KG_df['source_vector'].tolist())\n",
    "target_vectors = np.array(Rice_KG_df['target_vector'].tolist())\n",
    "\n",
    "# Concatenate source and target vectors as features\n",
    "X = np.concatenate([source_vectors, target_vectors], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(Rice_KG_df['relationship_type'])\n",
    "\n",
    "# Perform cross-validation\n",
    "dt_accuracy = cross_val_score(DecisionTreeClassifier(), X, y, cv=5)  # 5-fold cross-validation\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", dt_accuracy)\n",
    "print(\"Mean accuracy:\", np.mean(dt_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1396 - loss: 1.6877  \n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.5029 - loss: 1.4043\n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.7945 - loss: 1.1799\n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9046 - loss: 0.9211\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.8491 - loss: 0.8313\n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.9142 - loss: 0.5820\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9229 - loss: 0.4681\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.8942 - loss: 0.4543\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.8951 - loss: 0.4372\n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8777 - loss: 0.4704 \n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.8968 - loss: 0.3905\n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.8838 - loss: 0.4296\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.8795 - loss: 0.4267\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.8265 - loss: 0.5453\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.8873 - loss: 0.4035\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.8638 - loss: 0.4537\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.8751 - loss: 0.4142\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.8638 - loss: 0.4333\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.8664 - loss: 0.4258\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8873 - loss: 0.3714\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.8769 - loss: 0.3581\n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.9090 - loss: 0.3081\n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.8977 - loss: 0.3172\n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.8803 - loss: 0.3668\n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.9003 - loss: 0.2852\n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8821 - loss: 0.3295\n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.8847 - loss: 0.3052\n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.8925 - loss: 0.2858\n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.8769 - loss: 0.3118\n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.8882 - loss: 0.2735\n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.8612 - loss: 0.3391\n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8638 - loss: 0.3129\n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.8925 - loss: 0.2667\n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.8960 - loss: 0.2501\n",
      "Epoch 35/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.8925 - loss: 0.2672\n",
      "Epoch 36/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.9099 - loss: 0.2199\n",
      "Epoch 37/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.8838 - loss: 0.2750\n",
      "Epoch 38/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.8829 - loss: 0.2809\n",
      "Epoch 39/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8786 - loss: 0.2647\n",
      "Epoch 40/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.9072 - loss: 0.1989\n",
      "Epoch 41/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.8708 - loss: 0.2807\n",
      "Epoch 42/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.2902 \n",
      "Epoch 43/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.8532 - loss: 0.3179\n",
      "Epoch 44/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.8966 - loss: 0.2361\n",
      "Epoch 45/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.9107 - loss: 0.2025\n",
      "Epoch 46/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9235 - loss: 0.1658\n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.9059 - loss: 0.2236\n",
      "Epoch 48/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.9328 - loss: 0.1852\n",
      "Epoch 49/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.8957 - loss: 0.2161\n",
      "Epoch 50/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.9163 - loss: 0.1909\n",
      "Epoch 51/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.9135 - loss: 0.2187\n",
      "Epoch 52/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.8822 - loss: 0.2455\n",
      "Epoch 53/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.9118 - loss: 0.2232\n",
      "Epoch 54/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.9144 - loss: 0.2003\n",
      "Epoch 55/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.9335 - loss: 0.1590\n",
      "Epoch 56/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - accuracy: 0.9309 - loss: 0.1672\n",
      "Epoch 57/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.1782 \n",
      "Epoch 58/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.9309 - loss: 0.1562\n",
      "Epoch 59/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.9309 - loss: 0.1368\n",
      "Epoch 60/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.9256 - loss: 0.1379\n",
      "Epoch 61/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.9526 - loss: 0.1076\n",
      "Epoch 62/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.9170 - loss: 0.1676\n",
      "Epoch 63/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.9430 - loss: 0.1272\n",
      "Epoch 64/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.9521 - loss: 0.1513\n",
      "Epoch 65/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.9391 - loss: 0.1774\n",
      "Epoch 66/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.9460 - loss: 0.1515\n",
      "Epoch 67/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.9573 - loss: 0.1345\n",
      "Epoch 68/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.9564 - loss: 0.1433\n",
      "Epoch 69/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.9733 - loss: 0.1323\n",
      "Epoch 70/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.9837 - loss: 0.1363\n",
      "Epoch 71/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9733 - loss: 0.1321 \n",
      "Epoch 72/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.9837 - loss: 0.1160\n",
      "Epoch 73/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.9924 - loss: 0.1096\n",
      "Epoch 74/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.9837 - loss: 0.1219\n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.9924 - loss: 0.1102\n",
      "Epoch 76/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.9889 - loss: 0.1075\n",
      "Epoch 77/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.9837 - loss: 0.0850\n",
      "Epoch 78/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.9733 - loss: 0.1315\n",
      "Epoch 79/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.9950 - loss: 0.0769\n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 1.0000 - loss: 0.0974\n",
      "Epoch 81/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 1.0000 - loss: 0.0798\n",
      "Epoch 82/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 1.0000 - loss: 0.1042\n",
      "Epoch 83/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 1.0000 - loss: 0.0895\n",
      "Epoch 84/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0868\n",
      "Epoch 85/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 1.0000 - loss: 0.0766\n",
      "Epoch 86/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 1.0000 - loss: 0.0939\n",
      "Epoch 87/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 1.0000 - loss: 0.0724\n",
      "Epoch 88/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 1.0000 - loss: 0.0915\n",
      "Epoch 89/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 1.0000 - loss: 0.0735\n",
      "Epoch 90/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 1.0000 - loss: 0.0672\n",
      "Epoch 91/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 1.0000 - loss: 0.0621\n",
      "Epoch 92/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 1.0000 - loss: 0.0775\n",
      "Epoch 93/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 1.0000 - loss: 0.0768\n",
      "Epoch 94/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 1.0000 - loss: 0.0658\n",
      "Epoch 95/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 1.0000 - loss: 0.0681\n",
      "Epoch 96/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 1.0000 - loss: 0.0597\n",
      "Epoch 97/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0566 \n",
      "Epoch 98/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 1.0000 - loss: 0.0586\n",
      "Epoch 99/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 1.0000 - loss: 0.0639\n",
      "Epoch 100/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 1.0000 - loss: 0.0580\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9412 - loss: 0.2231\n",
      "Accuracy: 0.9411764740943909\n"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Concatenate source and target vectors as features\n",
    "X = np.concatenate([Rice_KG_df['source_vector'].values.tolist(), Rice_KG_df['target_vector'].values.tolist()], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(Rice_KG_df['relationship_type'])\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax') # Output layer with softmax activation for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # Use sparse categorical crossentropy for integer-encoded labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, nn_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", nn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2692 - loss: 1.6033  \n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7797 - loss: 1.3824\n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8728 - loss: 1.1353 \n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8398 - loss: 0.9134\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8638 - loss: 0.6801 \n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9081 - loss: 0.5171\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8647 - loss: 0.6615\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8899 - loss: 0.5298\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8508 - loss: 0.7181 \n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8578 - loss: 0.6291 \n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8786 - loss: 0.4932 \n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.8699 - loss: 0.4951\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.8387 - loss: 0.6437\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.8916 - loss: 0.3863\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.8951 - loss: 0.4342\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8873 - loss: 0.4935\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.8612 - loss: 0.5602\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.8934 - loss: 0.4198\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.8699 - loss: 0.6099\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.8882 - loss: 0.4144\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.8951 - loss: 0.3977\n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.9107 - loss: 0.3743\n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.8630 - loss: 0.4835\n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.8491 - loss: 0.5367\n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8951 - loss: 0.4062\n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8882 - loss: 0.3847 \n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.8994 - loss: 0.4234\n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.8647 - loss: 0.4535\n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.8664 - loss: 0.4651\n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.8664 - loss: 0.4838\n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.8578 - loss: 0.4448\n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.8526 - loss: 0.4631\n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.8647 - loss: 0.4586\n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.8942 - loss: 0.3333\n",
      "Epoch 35/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8769 - loss: 0.4624\n",
      "Epoch 36/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.8951 - loss: 0.3459\n",
      "Epoch 37/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.8638 - loss: 0.4051\n",
      "Epoch 38/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.9003 - loss: 0.2568\n",
      "Epoch 39/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.8977 - loss: 0.3387\n",
      "Epoch 40/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8968 - loss: 0.3707\n",
      "Epoch 41/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8923 - loss: 0.3385 \n",
      "Epoch 42/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.8803 - loss: 0.3033\n",
      "Epoch 43/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.8584 - loss: 0.4043\n",
      "Epoch 44/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.9055 - loss: 0.3130\n",
      "Epoch 45/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9012 - loss: 0.2570\n",
      "Epoch 46/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.8456 - loss: 0.4408\n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.8569 - loss: 0.3709\n",
      "Epoch 48/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.9131 - loss: 0.2817\n",
      "Epoch 49/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.8960 - loss: 0.2880\n",
      "Epoch 50/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.9287 - loss: 0.2520\n",
      "Epoch 51/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.8812 - loss: 0.2767\n",
      "Epoch 52/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9155 - loss: 0.2360\n",
      "Epoch 53/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.8862 - loss: 0.2872\n",
      "Epoch 54/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9215 - loss: 0.2396\n",
      "Epoch 55/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.8673 - loss: 0.2642\n",
      "Epoch 56/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.3098 \n",
      "Epoch 57/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.9111 - loss: 0.2362\n",
      "Epoch 58/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.8960 - loss: 0.2574\n",
      "Epoch 59/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.8699 - loss: 0.2620\n",
      "Epoch 60/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9088 - loss: 0.2377\n",
      "Epoch 61/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.9053 - loss: 0.2078\n",
      "Epoch 62/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.9076 - loss: 0.2719\n",
      "Epoch 63/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.9285 - loss: 0.1965\n",
      "Epoch 64/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.9083 - loss: 0.2774\n",
      "Epoch 65/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.8847 - loss: 0.2311\n",
      "Epoch 66/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.9465 - loss: 0.1493\n",
      "Epoch 67/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9193 - loss: 0.2291\n",
      "Epoch 68/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.8801 - loss: 0.2880\n",
      "Epoch 69/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.8747 - loss: 0.2157\n",
      "Epoch 70/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.8927 - loss: 0.2345\n",
      "Epoch 71/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.1786 \n",
      "Epoch 72/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9037 - loss: 0.1945 \n",
      "Epoch 73/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9779 - loss: 0.1622\n",
      "Epoch 74/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.9506 - loss: 0.1815\n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9515 - loss: 0.1608\n",
      "Epoch 76/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.9239 - loss: 0.1715\n",
      "Epoch 77/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1591\n",
      "Epoch 78/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.9228 - loss: 0.1597\n",
      "Epoch 79/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9384 - loss: 0.1705 \n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9111 - loss: 0.1873\n",
      "Epoch 81/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9413 - loss: 0.1615\n",
      "Epoch 82/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.9814 - loss: 0.1332\n",
      "Epoch 83/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9384 - loss: 0.1635 \n",
      "Epoch 84/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.1667 \n",
      "Epoch 85/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9727 - loss: 0.1102 \n",
      "Epoch 86/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9657 - loss: 0.1202 \n",
      "Epoch 87/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9837 - loss: 0.1463 \n",
      "Epoch 88/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9889 - loss: 0.1186 \n",
      "Epoch 89/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9950 - loss: 0.1093 \n",
      "Epoch 90/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9384 - loss: 0.1229\n",
      "Epoch 91/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.9384 - loss: 0.1436\n",
      "Epoch 92/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9837 - loss: 0.1316 \n",
      "Epoch 93/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9564 - loss: 0.1030\n",
      "Epoch 94/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.1134\n",
      "Epoch 95/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.9764 - loss: 0.1030\n",
      "Epoch 96/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9623 - loss: 0.1278 \n",
      "Epoch 97/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9623 - loss: 0.1137 \n",
      "Epoch 98/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9523 - loss: 0.1226\n",
      "Epoch 99/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9840 - loss: 0.0983 \n",
      "Epoch 100/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9837 - loss: 0.1319\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9412 - loss: 0.1679\n",
      "Accuracy: 0.9411764740943909\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "\n",
    "# Reshape the input data to be suitable for a 1D CNN\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(64, 3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(32, 3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(np.unique(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # Use sparse categorical crossentropy for integer-encoded labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, cnn_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", cnn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.2577 - loss: 1.5980\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.7732 - loss: 1.5233\n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9125 - loss: 1.4535\n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.8786 - loss: 1.3975\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.8647 - loss: 1.3247\n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.8821 - loss: 1.2431\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.8916 - loss: 1.1506\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.8899 - loss: 1.0703\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8664 - loss: 1.0184 \n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.8942 - loss: 0.8964\n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.8821 - loss: 0.8353\n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.8908 - loss: 0.7488\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8612 - loss: 0.7298\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.8421 - loss: 0.6918\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.8630 - loss: 0.6201\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8352 - loss: 0.6575\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.9038 - loss: 0.4813\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.9029 - loss: 0.4642\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.8725 - loss: 0.5200\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.8803 - loss: 0.4869\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8803 - loss: 0.4819\n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.8421 - loss: 0.5724\n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.8951 - loss: 0.4186\n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.8586 - loss: 0.5192\n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9125 - loss: 0.3612\n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9012 - loss: 0.4037\n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8474 - loss: 0.5131 \n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.9020 - loss: 0.3670\n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.8838 - loss: 0.4141\n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.8786 - loss: 0.4500\n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.8734 - loss: 0.4595\n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.8691 - loss: 0.4153\n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.8821 - loss: 0.4066\n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.8560 - loss: 0.4564\n",
      "Epoch 35/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.9012 - loss: 0.3587\n",
      "Epoch 36/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.8803 - loss: 0.3816\n",
      "Epoch 37/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.8474 - loss: 0.4745\n",
      "Epoch 38/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.8942 - loss: 0.3462\n",
      "Epoch 39/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.8699 - loss: 0.4128\n",
      "Epoch 40/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.8873 - loss: 0.3818\n",
      "Epoch 41/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.8882 - loss: 0.3630\n",
      "Epoch 42/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8855 - loss: 0.3485\n",
      "Epoch 43/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8621 - loss: 0.3840 \n",
      "Epoch 44/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.8795 - loss: 0.3926\n",
      "Epoch 45/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.9237 - loss: 0.2564\n",
      "Epoch 46/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9038 - loss: 0.3236\n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.8899 - loss: 0.3439\n",
      "Epoch 48/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.8873 - loss: 0.3065\n",
      "Epoch 49/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.8630 - loss: 0.3785\n",
      "Epoch 50/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.8474 - loss: 0.4272\n",
      "Epoch 51/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.8977 - loss: 0.3157\n",
      "Epoch 52/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.8855 - loss: 0.3526\n",
      "Epoch 53/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.8951 - loss: 0.3005\n",
      "Epoch 54/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.8890 - loss: 0.3288\n",
      "Epoch 55/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.8882 - loss: 0.3214\n",
      "Epoch 56/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.8879 - loss: 0.3602\n",
      "Epoch 57/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.9088 - loss: 0.2890\n",
      "Epoch 58/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.3069 \n",
      "Epoch 59/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.9413 - loss: 0.2743\n",
      "Epoch 60/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.9152 - loss: 0.3142\n",
      "Epoch 61/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.9378 - loss: 0.2714\n",
      "Epoch 62/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9309 - loss: 0.2830\n",
      "Epoch 63/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.8927 - loss: 0.3764\n",
      "Epoch 64/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.8688 - loss: 0.3749\n",
      "Epoch 65/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.8897 - loss: 0.2615\n",
      "Epoch 66/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.8818 - loss: 0.3085\n",
      "Epoch 67/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.8897 - loss: 0.2888\n",
      "Epoch 68/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.9209 - loss: 0.2070\n",
      "Epoch 69/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9166 - loss: 0.2284\n",
      "Epoch 70/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.8775 - loss: 0.2760\n",
      "Epoch 71/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.8770 - loss: 0.3361\n",
      "Epoch 72/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.9343 - loss: 0.2519\n",
      "Epoch 73/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9343 - loss: 0.2683\n",
      "Epoch 74/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.2586 \n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.9274 - loss: 0.2498\n",
      "Epoch 76/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.9413 - loss: 0.2220\n",
      "Epoch 77/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9352 - loss: 0.2258\n",
      "Epoch 78/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.9228 - loss: 0.2829\n",
      "Epoch 79/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.9315 - loss: 0.2584\n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.9462 - loss: 0.2588\n",
      "Epoch 81/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9575 - loss: 0.2219\n",
      "Epoch 82/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9141 - loss: 0.2649\n",
      "Epoch 83/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.9280 - loss: 0.2642\n",
      "Epoch 84/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.9254 - loss: 0.2559\n",
      "Epoch 85/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9465 - loss: 0.1806\n",
      "Epoch 86/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.9037 - loss: 0.2625\n",
      "Epoch 87/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.2042 \n",
      "Epoch 88/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9506 - loss: 0.2076\n",
      "Epoch 89/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9384 - loss: 0.2251\n",
      "Epoch 90/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.9549 - loss: 0.2011\n",
      "Epoch 91/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.9575 - loss: 0.1830\n",
      "Epoch 92/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.9280 - loss: 0.2063\n",
      "Epoch 93/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9610 - loss: 0.1532\n",
      "Epoch 94/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9616 - loss: 0.2015\n",
      "Epoch 95/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9567 - loss: 0.1596\n",
      "Epoch 96/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9341 - loss: 0.1708 \n",
      "Epoch 97/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.9506 - loss: 0.1806\n",
      "Epoch 98/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.9384 - loss: 0.1872\n",
      "Epoch 99/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9541 - loss: 0.1664 \n",
      "Epoch 100/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1695 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9412 - loss: 0.2472\n",
      "Accuracy: 0.9411764740943909\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Reshape the input data to be suitable for an RNN (assuming sequential data)\n",
    "X_train_rnn = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test_rnn = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')  # Adjust output units to match the number of unique classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy for integer-encoded labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the reshaped data\n",
    "model.fit(X_train_rnn, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model using the reshaped test data\n",
    "loss, rnn_accuracy = model.evaluate(X_test_rnn, y_test)\n",
    "print(\"Accuracy:\", rnn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the accuracy scores of four other models stored in variables\n",
    "\n",
    "# Define the model names\n",
    "model_names = ['Random Forest', 'Decision Tree', 'Neural Network', 'CNN', 'RNN']\n",
    "\n",
    "# Define the accuracy scores\n",
    "accuracy_scores = [np.mean(rf_accuracy), np.mean(dt_accuracy), nn_accuracy, cnn_accuracy, rnn_accuracy]\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, accuracy_scores, color=['blue', 'green', 'red', 'orange', 'purple'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Rice Knowledge Graph with ML/DL Model')\n",
    "plt.ylim(0, 1)  # Set the y-axis limits to ensure all bars are visible\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
