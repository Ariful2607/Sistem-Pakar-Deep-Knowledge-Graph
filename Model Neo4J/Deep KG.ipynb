{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://34.101.192.24:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"unej1234\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_vector</th>\n",
       "      <th>source_label</th>\n",
       "      <th>source_class</th>\n",
       "      <th>relationship_type</th>\n",
       "      <th>target_vector</th>\n",
       "      <th>target_label</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.03818255290389061, -0.015258912928402424, -...</td>\n",
       "      <td>Bulir terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.03753756731748581, 0.005460740067064762, -0...</td>\n",
       "      <td>Bulir pecah</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.03612148016691208, 0.0048484764993190765, 0...</td>\n",
       "      <td>Bulir berubah warna</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.03656195476651192, 0.02377898246049881, 0.0...</td>\n",
       "      <td>Bulir mengalami kerusakan</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03452454134821892, 0.04011273384094238, -0....</td>\n",
       "      <td>Gosong bulir</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.038021307438611984, -0.010079000145196915, ...</td>\n",
       "      <td>Malai terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03643496334552765, -0.020186755806207657, -...</td>\n",
       "      <td>Garis Merah</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>[0.038021307438611984, -0.010079000145196915, ...</td>\n",
       "      <td>Malai terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03919482231140137, -0.031110592186450958, 0...</td>\n",
       "      <td>Penggerek Batang Kuning</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>[0.033894460648298264, -0.014245453290641308, ...</td>\n",
       "      <td>Daun terdapat bercak</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03919482231140137, -0.031110592186450958, 0...</td>\n",
       "      <td>Penggerek Batang Kuning</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>[0.03758235648274422, 0.02068854123353958, 0.0...</td>\n",
       "      <td>Batang rapuh</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03914107382297516, -0.029383953660726547, -...</td>\n",
       "      <td>Rayap</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>[0.03786005824804306, -0.004899086430668831, 0...</td>\n",
       "      <td>Akar berlubang</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03914107382297516, -0.029383953660726547, -...</td>\n",
       "      <td>Rayap</td>\n",
       "      <td>[HamaPadi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>[0.03823630139231682, -0.01698555052280426, 0....</td>\n",
       "      <td>Pelepah mengalami kerusakan</td>\n",
       "      <td>[Gejala]</td>\n",
       "      <td>memilikiGejala</td>\n",
       "      <td>[0.03915898874402046, 0.03670716658234596, -0....</td>\n",
       "      <td>Hawar Pelepah</td>\n",
       "      <td>[PenyakitPadi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_vector  \\\n",
       "0    [0.03818255290389061, -0.015258912928402424, -...   \n",
       "1    [0.03753756731748581, 0.005460740067064762, -0...   \n",
       "2    [0.03612148016691208, 0.0048484764993190765, 0...   \n",
       "3    [0.03656195476651192, 0.02377898246049881, 0.0...   \n",
       "4    [0.038021307438611984, -0.010079000145196915, ...   \n",
       "..                                                 ...   \n",
       "131  [0.038021307438611984, -0.010079000145196915, ...   \n",
       "132  [0.033894460648298264, -0.014245453290641308, ...   \n",
       "133  [0.03758235648274422, 0.02068854123353958, 0.0...   \n",
       "134  [0.03786005824804306, -0.004899086430668831, 0...   \n",
       "135  [0.03823630139231682, -0.01698555052280426, 0....   \n",
       "\n",
       "                    source_label source_class relationship_type  \\\n",
       "0          Bulir terdapat bercak     [Gejala]    memilikiGejala   \n",
       "1                    Bulir pecah     [Gejala]    memilikiGejala   \n",
       "2            Bulir berubah warna     [Gejala]    memilikiGejala   \n",
       "3      Bulir mengalami kerusakan     [Gejala]    memilikiGejala   \n",
       "4          Malai terdapat bercak     [Gejala]    memilikiGejala   \n",
       "..                           ...          ...               ...   \n",
       "131        Malai terdapat bercak     [Gejala]    memilikiGejala   \n",
       "132         Daun terdapat bercak     [Gejala]    memilikiGejala   \n",
       "133                 Batang rapuh     [Gejala]    memilikiGejala   \n",
       "134               Akar berlubang     [Gejala]    memilikiGejala   \n",
       "135  Pelepah mengalami kerusakan     [Gejala]    memilikiGejala   \n",
       "\n",
       "                                         target_vector  \\\n",
       "0    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "1    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "2    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "3    [0.03452454134821892, 0.04011273384094238, -0....   \n",
       "4    [0.03643496334552765, -0.020186755806207657, -...   \n",
       "..                                                 ...   \n",
       "131  [0.03919482231140137, -0.031110592186450958, 0...   \n",
       "132  [0.03919482231140137, -0.031110592186450958, 0...   \n",
       "133  [0.03914107382297516, -0.029383953660726547, -...   \n",
       "134  [0.03914107382297516, -0.029383953660726547, -...   \n",
       "135  [0.03915898874402046, 0.03670716658234596, -0....   \n",
       "\n",
       "                target_label    target_class  \n",
       "0               Gosong bulir  [PenyakitPadi]  \n",
       "1               Gosong bulir  [PenyakitPadi]  \n",
       "2               Gosong bulir  [PenyakitPadi]  \n",
       "3               Gosong bulir  [PenyakitPadi]  \n",
       "4                Garis Merah  [PenyakitPadi]  \n",
       "..                       ...             ...  \n",
       "131  Penggerek Batang Kuning      [HamaPadi]  \n",
       "132  Penggerek Batang Kuning      [HamaPadi]  \n",
       "133                    Rayap      [HamaPadi]  \n",
       "134                    Rayap      [HamaPadi]  \n",
       "135            Hawar Pelepah  [PenyakitPadi]  \n",
       "\n",
       "[136 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_node_properties_and_relationships():\n",
    "    with driver.session() as session:\n",
    "        # Cypher query to fetch node properties and relationships\n",
    "        query = \"\"\"\n",
    "        MATCH (n)-[r]->(m)\n",
    "            WHERE any(label IN labels(n) WHERE label IN ['Gejala', 'PenyakitPadi', 'HamaPadi']) \n",
    "            AND any(label IN labels(m) WHERE label IN ['Gejala', 'PenyakitPadi', 'HamaPadi'])\n",
    "        RETURN \n",
    "        m.Vector AS source_vector, m.label AS source_label, labels(m) AS source_class, \n",
    "        type(r) AS relationship_type,\n",
    "        n.Vector AS target_vector, n.label AS target_label, labels(n) AS target_class\n",
    "\n",
    "        \"\"\"\n",
    "        result = session.run(query)\n",
    "        # Extract properties and relationships and store in DataFrame\n",
    "        df = pd.DataFrame([record.values() for record in result], columns=result.keys())\n",
    "        # Clean labels\n",
    "        df['source_class'] = df['source_class'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "        df['target_class'] = df['target_class'].apply(lambda entry: [item for item in entry if item not in [\"Resource\", \"NamedIndividual\"]])\n",
    "        return df\n",
    "\n",
    "# Call the function to extract node properties and relationships\n",
    "Rice_KG_df = extract_node_properties_and_relationships()\n",
    "\n",
    "# Print the DataFrame\n",
    "Rice_KG_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = pd.concat([Rice_KG_df] * 100, ignore_index=True)  # Adjust the multiplier (2 in this case) as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35024509803921566\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                  Bakanae       0.63      0.61      0.62       186\n",
      "       Bakteri Garis Daun       0.00      0.00      0.00       188\n",
      "           Belalang Sawah       0.70      0.59      0.64       131\n",
      "     Belatung Lalat Bibit       0.00      0.00      0.00        97\n",
      "            Bercak Coklat       0.48      0.21      0.29       144\n",
      "                     Blas       1.00      0.30      0.46       127\n",
      "Bulir mengalami kerusakan       0.00      0.00      0.00        28\n",
      "               Busuk Akar       0.49      0.79      0.61       150\n",
      "             Busuk Batang       0.53      0.74      0.62       110\n",
      "            Busuk Pelepah       1.00      0.78      0.88       126\n",
      "         Ganjur Padi Asia       0.00      0.00      0.00        70\n",
      "              Garis Merah       0.00      0.00      0.00       122\n",
      "             Gosong bulir       0.59      1.00      0.75       126\n",
      "      Hama Kupu-kupu Padi       0.38      0.36      0.37       165\n",
      "       Hawar Daun Bakteri       0.00      0.00      0.00       117\n",
      "      Hawar Malai Bakteri       0.17      0.27      0.21        88\n",
      "            Hawar Pelepah       0.49      1.00      0.66        27\n",
      "               Hispa Padi       0.00      0.00      0.00        85\n",
      "       Karat Garis Kuning       0.12      1.00      0.22        45\n",
      "              Kepik Ludah       1.00      0.33      0.50        88\n",
      "     Kumbang Tangkai Padi       0.00      0.00      0.00        91\n",
      "                Kutu Daun       0.00      0.00      0.00        95\n",
      "               Kutu Putih       0.00      0.00      0.00        58\n",
      "              Lalat Tunas       0.00      0.00      0.00       130\n",
      "               Lepuh Daun       1.00      0.65      0.79       100\n",
      "         Meloidogyne spp.       1.00      1.00      1.00        33\n",
      "  Penggerek Batang Kuning       0.00      0.00      0.00       139\n",
      "    Penggerek Batang Padi       0.29      0.66      0.40       167\n",
      "    Penggerek Batang Ungu       0.26      0.30      0.28        89\n",
      "     Penggulung Daun Padi       0.00      0.00      0.00       112\n",
      "           Phoma Sorghina       0.30      0.68      0.42        78\n",
      "                    Rayap       1.00      0.54      0.70        61\n",
      "                   Thrips       0.00      0.00      0.00        57\n",
      "         Tungau Daun Padi       0.11      0.27      0.16        91\n",
      "        Tungau Malai Padi       0.00      0.00      0.00        55\n",
      "                   Tungro       1.00      1.00      1.00        73\n",
      "              Ulat Grayak       0.25      1.00      0.40        23\n",
      "        Ulat Kantung Padi       0.00      0.00      0.00        33\n",
      "     Ulat Tanduk Tembakau       0.20      1.00      0.33        23\n",
      "      Virus Belang Kuning       0.00      0.00      0.00        99\n",
      "      Virus Kerdil Rumput       0.00      0.00      0.00        89\n",
      "     Wereng Batang Coklat       0.15      0.48      0.23        56\n",
      "             Wereng Hijau       0.05      1.00      0.10        24\n",
      "    Wereng Punggung Putih       0.16      0.56      0.25        84\n",
      "\n",
      "                 accuracy                           0.35      4080\n",
      "                macro avg       0.30      0.39      0.29      4080\n",
      "             weighted avg       0.33      0.35      0.30      4080\n",
      "\n",
      "Feature Importances: [0.85897356 0.14102644]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder_source = LabelEncoder()\n",
    "\n",
    "label_encoder_relationship = LabelEncoder()\n",
    "label_encoder_target = LabelEncoder()\n",
    "\n",
    "synthetic_data['source_label_encoded'] = label_encoder_source.fit_transform(synthetic_data['source_label'])\n",
    "synthetic_data['relationship_type_encoded'] = label_encoder_relationship.fit_transform(synthetic_data['relationship_type'])\n",
    "synthetic_data['target_label_encoded'] = label_encoder_target.fit_transform(synthetic_data['target_label'])\n",
    "\n",
    "# Define the feature matrix and target vector\n",
    "X = synthetic_data[['source_label_encoded', 'relationship_type_encoded']]\n",
    "y = synthetic_data['target_label_encoded']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=label_encoder_target.classes_)\n",
    "\n",
    "# Calculate feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')\n",
    "print(f'Feature Importances: {feature_importances}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35024509803921566\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                  Bakanae       0.63      0.61      0.62       186\n",
      "       Bakteri Garis Daun       0.00      0.00      0.00       188\n",
      "           Belalang Sawah       0.70      0.59      0.64       131\n",
      "     Belatung Lalat Bibit       0.00      0.00      0.00        97\n",
      "            Bercak Coklat       0.27      0.38      0.31       144\n",
      "                     Blas       1.00      0.30      0.46       127\n",
      "Bulir mengalami kerusakan       0.00      0.00      0.00        28\n",
      "               Busuk Akar       0.49      0.79      0.61       150\n",
      "             Busuk Batang       0.53      0.74      0.62       110\n",
      "            Busuk Pelepah       1.00      0.78      0.88       126\n",
      "         Ganjur Padi Asia       0.00      0.00      0.00        70\n",
      "              Garis Merah       0.09      0.20      0.13       122\n",
      "             Gosong bulir       0.59      1.00      0.75       126\n",
      "      Hama Kupu-kupu Padi       0.38      0.36      0.37       165\n",
      "       Hawar Daun Bakteri       0.00      0.00      0.00       117\n",
      "      Hawar Malai Bakteri       0.00      0.00      0.00        88\n",
      "            Hawar Pelepah       0.49      1.00      0.66        27\n",
      "               Hispa Padi       0.00      0.00      0.00        85\n",
      "       Karat Garis Kuning       0.12      1.00      0.22        45\n",
      "              Kepik Ludah       1.00      0.33      0.50        88\n",
      "     Kumbang Tangkai Padi       0.00      0.00      0.00        91\n",
      "                Kutu Daun       0.00      0.00      0.00        95\n",
      "               Kutu Putih       0.00      0.00      0.00        58\n",
      "              Lalat Tunas       0.00      0.00      0.00       130\n",
      "               Lepuh Daun       1.00      0.65      0.79       100\n",
      "         Meloidogyne spp.       1.00      1.00      1.00        33\n",
      "  Penggerek Batang Kuning       0.00      0.00      0.00       139\n",
      "    Penggerek Batang Padi       0.24      0.82      0.37       167\n",
      "    Penggerek Batang Ungu       0.26      0.30      0.28        89\n",
      "     Penggulung Daun Padi       0.00      0.00      0.00       112\n",
      "           Phoma Sorghina       0.30      0.68      0.42        78\n",
      "                    Rayap       1.00      0.54      0.70        61\n",
      "                   Thrips       0.00      0.00      0.00        57\n",
      "         Tungau Daun Padi       0.11      0.27      0.16        91\n",
      "        Tungau Malai Padi       0.00      0.00      0.00        55\n",
      "                   Tungro       1.00      1.00      1.00        73\n",
      "              Ulat Grayak       0.25      1.00      0.40        23\n",
      "        Ulat Kantung Padi       0.00      0.00      0.00        33\n",
      "     Ulat Tanduk Tembakau       0.20      1.00      0.33        23\n",
      "      Virus Belang Kuning       0.00      0.00      0.00        99\n",
      "      Virus Kerdil Rumput       0.00      0.00      0.00        89\n",
      "     Wereng Batang Coklat       0.00      0.00      0.00        56\n",
      "             Wereng Hijau       0.05      1.00      0.10        24\n",
      "    Wereng Punggung Putih       1.00      0.26      0.42        84\n",
      "\n",
      "                 accuracy                           0.35      4080\n",
      "                macro avg       0.31      0.38      0.29      4080\n",
      "             weighted avg       0.33      0.35      0.30      4080\n",
      "\n",
      "Feature Importances: [0.86862701 0.13137299]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=label_encoder_target.classes_)\n",
    "\n",
    "# Calculate feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')\n",
    "print(f'Feature Importances: {feature_importances}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0s/step - accuracy: 0.4070 - loss: 1.7730   \n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8918 - loss: 1.7127 \n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9432 - loss: 1.6337  \n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 1.5460 \n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9505 - loss: 1.4103  \n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9190 - loss: 1.2702\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9152 - loss: 1.0930  \n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.9113 - loss: 0.8860\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9307 - loss: 0.6638  \n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step - accuracy: 0.9246 - loss: 0.5328\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.4115 \n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.9035 - loss: 0.4692\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9376 - loss: 0.3295 \n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9396 - loss: 0.3216  \n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9392 - loss: 0.3012 \n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9440 - loss: 0.2747\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9341 - loss: 0.3228 \n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - accuracy: 0.9321 - loss: 0.3359\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9385 - loss: 0.3100  \n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8879 - loss: 0.4785  \n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9117 - loss: 0.3861  \n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9545 - loss: 0.2299\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.3660 \n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9144 - loss: 0.3702  \n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9194 - loss: 0.3410  \n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9087 - loss: 0.3892  \n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9323 - loss: 0.3147  \n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.3321 \n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9250 - loss: 0.3463  \n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9317 - loss: 0.3249 \n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9061 - loss: 0.3634  \n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.3778 \n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9397 - loss: 0.2497  \n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.9263 - loss: 0.3085\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8830 - loss: 0.4765  \n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137us/step - accuracy: 0.9272 - loss: 0.3208\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9418 - loss: 0.2420  \n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9037 - loss: 0.3516 \n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9300 - loss: 0.3173  \n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9580 - loss: 0.1987 \n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9066 - loss: 0.3399  \n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8892 - loss: 0.4133 \n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9064 - loss: 0.3269  \n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9437 - loss: 0.2592 \n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9265 - loss: 0.2859  \n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.2403 \n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.9165 - loss: 0.3132\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9505 - loss: 0.2068 \n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.9271 - loss: 0.2993\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9259 - loss: 0.2747\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9407 - loss: 0.2569 \n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9208 - loss: 0.3018  \n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2938 \n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8863 - loss: 0.4115  \n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9226 - loss: 0.2758  \n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9282 - loss: 0.2765  \n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8954 - loss: 0.3600  \n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: 0.3417 \n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9104 - loss: 0.3108  \n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.3572 \n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9370 - loss: 0.2463  \n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.3664 \n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9112 - loss: 0.2737  \n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9428 - loss: 0.2202 \n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8924 - loss: 0.3478  \n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9220 - loss: 0.2954  \n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.8909 - loss: 0.3261\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.9054 - loss: 0.2985\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9367 - loss: 0.2053 \n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9321 - loss: 0.2456  \n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.2298 \n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9409 - loss: 0.2130  \n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9304 - loss: 0.2515 \n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9310 - loss: 0.2116  \n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.2594 \n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9492 - loss: 0.1840  \n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9304 - loss: 0.2305 \n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.9091 - loss: 0.2692\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.2345 \n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8944 - loss: 0.3008 \n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9191 - loss: 0.2468  \n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9394 - loss: 0.1761  \n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9359 - loss: 0.1882  \n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9000 - loss: 0.2901  \n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1543 \n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9272 - loss: 0.2152  \n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9431 - loss: 0.1954 \n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9217 - loss: 0.2172  \n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9041 - loss: 0.2545  \n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190us/step - accuracy: 0.9363 - loss: 0.2194\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9161 - loss: 0.2141  \n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9112 - loss: 0.2001  \n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9317 - loss: 0.2190  \n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9057 - loss: 0.2385\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9327 - loss: 0.1814  \n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9198 - loss: 0.2072  \n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9208 - loss: 0.1943\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9394 - loss: 0.1591  \n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.2249 \n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9213 - loss: 0.1789  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.8929 - loss: 0.5516\n",
      "Accuracy: 0.8928571343421936\n"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Concatenate source and target vectors as features\n",
    "X = np.concatenate([Rice_KG_df['source_vector'].values.tolist(), Rice_KG_df['target_vector'].values.tolist()], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(Rice_KG_df['relationship_type'])\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax') # Output layer with softmax activation for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # Use sparse categorical crossentropy for integer-encoded labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, nn_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", nn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5620 - loss: 1.7810      \n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 1.6881 \n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 1.5011 \n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9015 - loss: 1.1398 \n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9243 - loss: 0.6345  \n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step - accuracy: 0.9375 - loss: 0.3588\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.3709 \n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9202 - loss: 0.3903 \n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.3128 \n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9276 - loss: 0.4166 \n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9312 - loss: 0.3465  \n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9194 - loss: 0.3941  \n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.2788 \n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.4040 \n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9428 - loss: 0.3654 \n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9246 - loss: 0.4547 \n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9248 - loss: 0.4077 \n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.4568 \n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.4311 \n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9320 - loss: 0.3177 \n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9204 - loss: 0.3136 \n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8957 - loss: 0.4819 \n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.2980 \n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9234 - loss: 0.3930 \n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.3825 \n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.9379 - loss: 0.2975\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9320 - loss: 0.4176 \n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.2643 \n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.3284 \n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9350 - loss: 0.3391 \n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.3353 \n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9405 - loss: 0.3377  \n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9526 - loss: 0.2640  \n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.3631 \n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9018 - loss: 0.5213 \n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9298 - loss: 0.4069 \n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9272 - loss: 0.3654 \n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9383 - loss: 0.3173 \n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.4048 \n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.3342 \n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - accuracy: 0.9479 - loss: 0.3127\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9346 - loss: 0.3294\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9233 - loss: 0.3949  \n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9384 - loss: 0.3001  \n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132us/step - accuracy: 0.9392 - loss: 0.3006\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.3264 \n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.2450 \n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9272 - loss: 0.3475 \n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9311 - loss: 0.3128 \n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60us/step - accuracy: 0.9638 - loss: 0.2059\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step - accuracy: 0.8976 - loss: 0.4742\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.3109 \n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 0.3538 \n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8937 - loss: 0.4632 \n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.9515 - loss: 0.2731\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9207 - loss: 0.3656 \n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.3636 \n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.4524 \n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9093 - loss: 0.4621  \n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.5040 \n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9450 - loss: 0.2704 \n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.2804 \n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.3794 \n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9113 - loss: 0.4239  \n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9496 - loss: 0.2751\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9385 - loss: 0.3141  \n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9341 - loss: 0.3111 \n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.2945 \n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.3012 \n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.3159 \n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.3976 \n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9146 - loss: 0.3725  \n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.9196 - loss: 0.4243\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.2787 \n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.3266 \n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9304 - loss: 0.3590 \n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.4036 \n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9265 - loss: 0.3257  \n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.9168 - loss: 0.3693\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.3803 \n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.4064 \n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.9122 - loss: 0.3803\n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.3036 \n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9366 - loss: 0.3365 \n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8668 - loss: 0.6266 \n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.3741 \n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.2736 \n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.4932 \n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9320 - loss: 0.3050  \n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.3332 \n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.3452 \n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9135 - loss: 0.4182 \n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9371 - loss: 0.2757 \n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9454 - loss: 0.2816\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9448 - loss: 0.2815\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9330 - loss: 0.3468 \n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.4464 \n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9216 - loss: 0.3774  \n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247us/step - accuracy: 0.9336 - loss: 0.3074\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9501 - loss: 0.2654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8929 - loss: 0.6250\n",
      "Accuracy: 0.8928571343421936\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "\n",
    "# Reshape the input data to be suitable for a 1D CNN\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(64, 3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(32, 3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(np.unique(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # Use sparse categorical crossentropy for integer-encoded labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, cnn_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", cnn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ariful\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396us/step - accuracy: 0.5025 - loss: 1.7873\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9607 - loss: 1.7626  \n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 1.7384 \n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9488 - loss: 1.7099 \n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9269 - loss: 1.6828 \n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9744 - loss: 1.6414 \n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.9478 - loss: 1.6075\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 1.5712 \n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.9292 - loss: 1.5281\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 1.4738 \n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.9555 - loss: 1.4158\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 1.3518 \n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9570 - loss: 1.2958\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9426 - loss: 1.2408 \n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9537 - loss: 1.1674\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 1.0982 \n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.9329 - loss: 1.0465\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9681 - loss: 0.9340 \n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9426 - loss: 0.8933  \n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.8465 \n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9558 - loss: 0.7473  \n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.6709 \n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9466 - loss: 0.6477  \n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9443 - loss: 0.5951 \n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9607 - loss: 0.5130  \n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9443 - loss: 0.5113 \n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9689 - loss: 0.4203  \n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9351 - loss: 0.4651  \n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9510 - loss: 0.4037  \n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.9391 - loss: 0.4116\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9354 - loss: 0.4061  \n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.3105 \n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9774 - loss: 0.2529  \n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.3126 \n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9774 - loss: 0.2256  \n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9448 - loss: 0.3093 \n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9585 - loss: 0.2631 \n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9495 - loss: 0.2813 \n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104us/step - accuracy: 0.9629 - loss: 0.2361\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.2539 \n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9589 - loss: 0.2433  \n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9699 - loss: 0.1973  \n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.2054 \n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.2615 \n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9704 - loss: 0.1902 \n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9734 - loss: 0.1762  \n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9198 - loss: 0.3460 \n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9589 - loss: 0.2162  \n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9426 - loss: 0.2715 \n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.9470 - loss: 0.2560\n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9426 - loss: 0.2726 \n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9664 - loss: 0.1885  \n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9518 - loss: 0.2396 \n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step - accuracy: 0.9607 - loss: 0.1987\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9336 - loss: 0.2944 \n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9257 - loss: 0.3139  \n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.2093 \n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9637 - loss: 0.1867 \n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9500 - loss: 0.2341\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9537 - loss: 0.2197 \n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9354 - loss: 0.2863  \n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9704 - loss: 0.1604 \n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9780 - loss: 0.1335  \n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.2322 \n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9402 - loss: 0.2577  \n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1965 \n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - accuracy: 0.9347 - loss: 0.2724\n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.2409 \n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9693 - loss: 0.1548  \n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9681 - loss: 0.1602 \n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9366 - loss: 0.2665  \n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9351 - loss: 0.2729 \n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9555 - loss: 0.2009  \n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231us/step - accuracy: 0.9329 - loss: 0.2713\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9607 - loss: 0.1871  \n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9513 - loss: 0.2197  \n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8964 - loss: 0.3846  \n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9314 - loss: 0.2770\n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9537 - loss: 0.2073 \n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9637 - loss: 0.1732  \n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.9592 - loss: 0.1959\n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9470 - loss: 0.2128 \n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9681 - loss: 0.1483  \n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9240 - loss: 0.2949 \n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9492 - loss: 0.2043  \n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.9492 - loss: 0.2128\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9332 - loss: 0.2795 \n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9551 - loss: 0.1899  \n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9381 - loss: 0.2540  \n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.9580 - loss: 0.1744\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9559 - loss: 0.1839  \n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273us/step - accuracy: 0.9656 - loss: 0.1507\n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9373 - loss: 0.2526  \n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9426 - loss: 0.2372 \n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.2235 \n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.9536 - loss: 0.1973\n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9106 - loss: 0.3342 \n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151us/step - accuracy: 0.9577 - loss: 0.1760\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9726 - loss: 0.1282 \n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9455 - loss: 0.2131  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.8608 - loss: 0.7616   \n",
      "Accuracy: 0.8536585569381714\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Function to safely evaluate a string representation of a list\n",
    "def safe_eval(x):\n",
    "    if isinstance(x, str):\n",
    "        return ast.literal_eval(x)\n",
    "    return x\n",
    "\n",
    "# Apply the safe_eval function to convert vector columns from string to list (if necessary)\n",
    "Rice_KG_df['source_vector'] = Rice_KG_df['source_vector'].apply(safe_eval)\n",
    "Rice_KG_df['target_vector'] = Rice_KG_df['target_vector'].apply(safe_eval)\n",
    "\n",
    "# Concatenate source and target vectors as features\n",
    "source_vectors = np.array(Rice_KG_df['source_vector'].tolist())\n",
    "target_vectors = np.array(Rice_KG_df['target_vector'].tolist())\n",
    "X = np.concatenate([source_vectors, target_vectors], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(Rice_KG_df['relationship_type'])\n",
    "\n",
    "# Reshape data for LSTM (samples, timesteps, features)\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Determine the number of unique classes\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(num_classes, activation='softmax')  # Output layer with softmax activation for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy for integer-encoded labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, rnn_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", rnn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the accuracy scores of four other models stored in variables\n",
    "\n",
    "# Define the model names\n",
    "model_names = ['Random Forest', 'Decision Tree', 'Neural Network', 'CNN', 'RNN']\n",
    "\n",
    "# Define the accuracy scores\n",
    "accuracy_scores = [np.mean(rf_accuracy), np.mean(dt_accuracy), nn_accuracy, cnn_accuracy, rnn_accuracy]\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, accuracy_scores, color=['blue', 'green', 'red', 'orange', 'purple'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Rice Knowledge Graph with ML/DL Model')\n",
    "plt.ylim(0, 1)  # Set the y-axis limits to ensure all bars are visible\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
